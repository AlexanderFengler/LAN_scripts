{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9b9d212-5fa7-4b88-b57d-ce2957e5a586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import pickle\n",
    "import gzip\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "110673dc-3971-4036-b373-1f2687cd0eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"data_alt\")\n",
    "PATH = DATA_PATH / \"mnist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdce3f8f-6202-4d47-896d-f5fd4c900c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"https://github.com/pytorch/tutorials/raw/master/_static/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "        content = requests.get(URL + FILENAME).content\n",
    "        (PATH / FILENAME).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92d02f5f-2572-4f45-933a-f109a57a20de",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6efecc82-4cc8-498f-b7d8-ffd16c54658b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2e9b644990>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.imshow(x_train[0].reshape((28, 28)), cmap = 'seismic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac07b937-1623-407f-aa5e-81a337c8d557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]) tensor([5, 0, 4,  ..., 8, 4, 8])\n",
      "torch.Size([50000, 784])\n",
      "tensor(0) tensor(9)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_valid, y_valid = map(\n",
    "    torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
    ")\n",
    "n, c = x_train.shape\n",
    "print(x_train, y_train)\n",
    "print(x_train.shape)\n",
    "print(y_train.min(), y_train.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9df964bd-0561-4032-a9b0-8ce5f3a8eb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.randn(784, 10) / math.sqrt(784)\n",
    "weights.requires_grad_()\n",
    "bias = torch.zeros(10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4355ff0-b25b-41d9-a282-f0050029439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - x.exp().sum(-1).log().unsqueeze(-1)\n",
    "\n",
    "def model(xb):\n",
    "    return log_softmax(xb @ weights + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90d7e262-629a-4427-9f30-8d21e2fdca6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.5515, -2.0431, -2.3339, -2.6590, -1.7946, -2.3924, -2.5395, -1.9613,\n",
      "        -2.5574, -2.6479], grad_fn=<SelectBackward>) torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "bs = 64\n",
    "xb = x_train[0:bs]\n",
    "preds = model(xb)\n",
    "#preds[0], preds.shape\n",
    "print(preds[0], preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de81ab5c-44bc-427e-ba15-c3472aadc83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(input, target):\n",
    "    return -input[range(target.shape[0]), target].mean()\n",
    "\n",
    "loss_func = nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77a66c96-574e-41b1-b3fb-d2d5d5c7f906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4287, grad_fn=<NegBackward>)\n"
     ]
    }
   ],
   "source": [
    "yb = y_train[0:bs]\n",
    "print(loss_func(preds, yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8769329-eb44-4f42-ad3c-fece8164186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, yb):\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds == yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebd2739d-f863-4f3e-a48e-13638e753340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0156)\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(preds, yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e2714ef-d19b-404b-b8a9-f5808b7e5813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(preds, yb).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "760a3eaf-adb7-4420-ae7b-7b3bb2bfc7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "lr = 0.5  # learning rate\n",
    "epochs = 10  # how many epochs to train for\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(epoch)\n",
    "    for i in range((n - 1) // bs + 1):\n",
    "        #         set_trace()\n",
    "        start_i = i * bs\n",
    "        end_i = start_i + bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            weights -= weights.grad * lr\n",
    "            bias -= bias.grad * lr\n",
    "            weights.grad.zero_()\n",
    "            bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c83ff626-d67a-40ed-bed7-cfec2cf09851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0555, grad_fn=<NegBackward>) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d513c20-f67e-43c0-8a98-71ed762c0be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "loss_func = F.cross_entropy\n",
    "\n",
    "def model(xb):\n",
    "    return xb @ weights + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "013a2d3c-7e06-456c-a0b6-17878d7ecdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0555, grad_fn=<NllLossBackward>) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "561d3145-1bc3-4e83-ba54-a7aa01a85ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Mnist_Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(784, 10) / math.sqrt(784))\n",
    "        self.bias = nn.Parameter(torch.zeros(10))\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return xb @ self.weights + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac87ee1a-8950-4391-ad9e-672a50a31b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Mnist_Logistic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cade3ddf-e3bb-4e39-a2e6-c29d9129ad22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2919, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e867a0e-6477-472e-9fc4-f48d41393f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for i in range((n - 1) // bs + 1):\n",
    "            start_i = i * bs\n",
    "            end_i = start_i + bs\n",
    "            xb = x_train[start_i:end_i]\n",
    "            yb = y_train[start_i:end_i]\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p -= p.grad * lr\n",
    "                model.zero_grad()\n",
    "\n",
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a945bea-8f8d-478a-94b2-b716f483862b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0550, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a162b70-b53c-4378-855a-e5f68c0f65c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refactor again\n",
    "\n",
    "class Mnist_Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(784, 10)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.lin(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a036dd13-aaf6-4cd9-8b58-9dbb3161fccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2678, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = Mnist_Logistic()\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53542a21-48b2-4207-84cb-0b0cad0e5de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0552, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "fit()\n",
    "\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75a5dfa3-ddd4-415c-8219-ec5cc7031d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "300710bc-b863-49ea-ab87-e252759bce79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3580, grad_fn=<NllLossBackward>)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "tensor(0.0551, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    model = Mnist_Logistic()\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "model, opt = get_model()\n",
    "print(loss_func(model(xb), yb))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(epoch)\n",
    "    for i in range((n - 1) // bs + 1):\n",
    "        start_i = i * bs\n",
    "        end_i = start_i + bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a76de240-fe56-4e5c-8608-bba0ee88c566",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fcf3db77-7ab8-41be-9ed0-127ea8ae2ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65ea0975-0ed5-47c0-842c-529f12343ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb = x_train[start_i:end_i]\n",
    "yb = y_train[start_i:end_i]\n",
    "xb, yb = train_ds[i*bs : i*bs+bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eaebe5ca-d4b7-4c0e-b9e8-f20b3f9a7fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = train_ds[i*bs : i*bs+bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c4ad2b3-bf27-4791-898b-2f5162d942ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "tensor(0.0552, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(epoch)\n",
    "    for i in range((n - 1) // bs + 1):\n",
    "        xb, yb = train_ds[i * bs: i * bs + bs]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a161d7ff-a1d7-4c97-8188-7a6696e28368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on TensorDataset in module torch.utils.data.dataset object:\n",
      "\n",
      "class TensorDataset(Dataset)\n",
      " |  TensorDataset(*args, **kwds)\n",
      " |  \n",
      " |  Dataset wrapping tensors.\n",
      " |  \n",
      " |  Each sample will be retrieved by indexing tensors along the first dimension.\n",
      " |  \n",
      " |  Args:\n",
      " |      *tensors (Tensor): tensors that have the same size of the first dimension.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      TensorDataset\n",
      " |      Dataset\n",
      " |      typing.Generic\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |  \n",
      " |  __init__(self, *tensors: torch.Tensor) -> None\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'tensors': typing.Tuple[torch.Tensor, ...]}\n",
      " |  \n",
      " |  __orig_bases__ = (torch.utils.data.dataset.Dataset[typing.Tuple[torch....\n",
      " |  \n",
      " |  __parameters__ = ()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Dataset:\n",
      " |  \n",
      " |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from Dataset:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __class_getitem__(params) from builtins.type\n",
      " |  \n",
      " |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      " |      This method is called when a class is subclassed.\n",
      " |      \n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwds)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d5b41429-ec32-4b87-9603-5ead263d5fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size = bs, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8b6f024-5799-4f14-83b3-ab4a2e2cd1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "tensor(0.0555, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(epoch)\n",
    "    for xb, yb in train_dl:\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25503c20-ec65-4f54-bf8e-c56d226149b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "\n",
    "valid_ds = TensorDataset(x_valid, y_valid)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41985043-7471-4c5e-aea7-c11fdc54a5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0 tensor(0.3588)\n",
      "1\n",
      "1 tensor(0.3202)\n",
      "2\n",
      "2 tensor(0.2717)\n",
      "3\n",
      "3 tensor(0.2961)\n",
      "4\n",
      "4 tensor(0.2767)\n",
      "5\n",
      "5 tensor(0.3522)\n",
      "6\n",
      "6 tensor(0.2676)\n",
      "7\n",
      "7 tensor(0.2922)\n",
      "8\n",
      "8 tensor(0.2765)\n",
      "9\n",
      "9 tensor(0.2691)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(epoch)\n",
    "    model.train()\n",
    "    for xb, yb in train_dl:\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_loss = sum(loss_func(model(xb), yb) for xb, yb in valid_dl)\n",
    "\n",
    "    print(epoch, valid_loss / len(valid_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7f1a6876-a63d-439e-8a49-6579d8c2456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff384a43-33d7-4820-91c2-c7174b1efbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "\n",
    "        print(epoch, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2630c4bd-2794-4eb2-8fb5-b7350374afc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "        DataLoader(valid_ds, batch_size=bs * 2),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "05b223b4-1fc8-4656-9fac-aa6a11765f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.3074694025397301\n",
      "1 0.2996636783242226\n",
      "2 0.2829707953214645\n",
      "3 0.3506061047434807\n",
      "4 0.27505996741056443\n",
      "5 0.27586731004714965\n",
      "6 0.3138345586538315\n",
      "7 0.27726793846488\n",
      "8 0.274765381526947\n",
      "9 0.2810439167618752\n"
     ]
    }
   ],
   "source": [
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "model, opt = get_model()\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "77dd8686-f2c5-449f-84a5-15e558cfb132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "class Mnist_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        xb = xb.view(-1, 1, 28, 28)\n",
    "        xb = F.relu(self.conv1(xb))\n",
    "        xb = F.relu(self.conv2(xb))\n",
    "        xb = F.relu(self.conv3(xb))\n",
    "        xb = F.avg_pool2d(xb, 4)\n",
    "        return xb.view(-1, xb.size(1))\n",
    "\n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "61b17c8a-3055-4cff-bf60-b0cea075a15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.36925131170749664\n",
      "1 0.23147286533117295\n",
      "2 0.18116162124872207\n",
      "3 0.16373501567840576\n",
      "4 0.19436325995922088\n",
      "5 0.1370927269101143\n",
      "6 0.1392441325068474\n",
      "7 0.11812602360546588\n",
      "8 0.1204397741317749\n",
      "9 0.11342527024745941\n"
     ]
    }
   ],
   "source": [
    "model = Mnist_CNN()\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aaa9bfff-d252-4bb1-ac69-bc6e37718085",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n",
    "\n",
    "\n",
    "def preprocess(x):\n",
    "    return x.view(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c8879bc6-ad3c-4bcb-931f-b8a8517d38de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    return x.view(-1, 1, 28, 28), y\n",
    "\n",
    "\n",
    "class WrappedDataLoader:\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    def __iter__(self):\n",
    "        batches = iter(self.dl)\n",
    "        for b in batches:\n",
    "            yield (self.func(*b))\n",
    "\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
    "valid_dl = WrappedDataLoader(valid_dl, preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "87ec18e8-2a66-4790-8def-5d21936527ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d(1),\n",
    "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
    ")\n",
    "\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "11b3c054-7b10-44ca-b5d2-e8d08822fe20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.3531205452263355\n",
      "1 0.22795068334639074\n",
      "2 0.22287103703022004\n",
      "3 0.19055086073279381\n",
      "4 0.17168541347980498\n",
      "5 0.1596343122214079\n",
      "6 0.14258123113960028\n",
      "7 0.14867576576471328\n",
      "8 0.14785299591720105\n",
      "9 0.13324177740216256\n"
     ]
    }
   ],
   "source": [
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8be6abe9-db8b-4058-b519-d9dff8832c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Using GPU\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e0486d63-cad2-4967-9f7e-94ed3725e23c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "16d62768-b652-4b6e-b0ad-6fa8ccd06c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    return x.view(-1, 1, 28, 28).to(dev), y.to(dev)\n",
    "\n",
    "\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
    "valid_dl = WrappedDataLoader(valid_dl, preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "679f6d22-e70f-45b9-8fe4-b9c5828a9799",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(dev)\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4dcb9b58-7f58-4e46-abf3-8cba6b33ffbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.1303500663250685\n",
      "1 0.12369029915034771\n",
      "2 0.13063027766346932\n",
      "3 0.13412892690002917\n",
      "4 0.12622670190483332\n",
      "5 0.12327847203910351\n",
      "6 0.14302172850891948\n",
      "7 0.12058610234111547\n",
      "8 0.12338311394006014\n",
      "9 0.12314812543205916\n"
     ]
    }
   ],
   "source": [
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3dc35d-8311-43e9-8ee2-b752ed879887",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lanfactory",
   "language": "python",
   "name": "lanfactory"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
