{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be7b9564-be61-46d4-9e86-8cc013f99654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing sys\n",
      "importing os\n",
      "importing copy\n",
      "importing lanfactory\n",
      "importing ssms\n"
     ]
    }
   ],
   "source": [
    "# Append system path to include the config scripts\n",
    "import sys\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "print('importing lanfactory')\n",
    "import lanfactory\n",
    "\n",
    "print('importing ssms')\n",
    "import ssms\n",
    "\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "from config import *\n",
    "\n",
    "import tensorflow\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa9cfcf-8457-457b-8d83-4cd25f857bcc",
   "metadata": {},
   "source": [
    "# DATA GENERATOR CONFIGS\n",
    "#### Note: Look into the ssms package documentation to get a better idea about the kinds of configs that you need for different kinds of training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "211e022b-28b8-4ad2-8f50-3d3dc28f364b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_folder': 'data/lan_mlp/',\n",
       " 'dgp_list': 'ddm',\n",
       " 'nbins': 0,\n",
       " 'n_samples': 100000,\n",
       " 'n_parameter_sets': 10000,\n",
       " 'n_parameter_sets_rejected': 100,\n",
       " 'n_training_samples_by_parameter_set': 1000,\n",
       " 'max_t': 20.0,\n",
       " 'delta_t': 0.001,\n",
       " 'pickleprotocol': 4,\n",
       " 'n_cpus': 'all',\n",
       " 'kde_data_mixture_probabilities': [0.8, 0.1, 0.1],\n",
       " 'simulation_filters': {'mode': 20,\n",
       "  'choice_cnt': 5,\n",
       "  'mean_rt': 15,\n",
       "  'std': 0,\n",
       "  'mode_cnt_rel': 0.6},\n",
       " 'negative_rt_cutoff': -66.77497,\n",
       " 'n_subruns': 10,\n",
       " 'bin_pointwise': False,\n",
       " 'separate_response_channels': False}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssms.config.data_generator_config['lan']['mlp']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce94559-7e07-4247-8203-5ed60d7331be",
   "metadata": {},
   "source": [
    "### Define Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3e843d7-5682-402e-b393-d7ae9fbe09a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found folder:  /users\n",
      "Moving on...\n",
      "Found folder:  /users/afengler\n",
      "Moving on...\n",
      "Found folder:  /users/afengler/data\n",
      "Moving on...\n",
      "Found folder:  /users/afengler/data/proj_lan_pipeline\n",
      "Moving on...\n",
      "Found folder:  /users/afengler/data/proj_lan_pipeline/LAN_scripts\n",
      "Moving on...\n",
      "Found folder:  /users/afengler/data/proj_lan_pipeline/LAN_scripts/config_files\n",
      "Moving on...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_config': {'name': 'full_ddm',\n",
       "  'params': ['v', 'a', 'z', 't', 'sz', 'sv', 'st'],\n",
       "  'param_bounds': [[-3.0, 0.3, 0.3, 0.25, 0.001, 0.001, 0.001],\n",
       "   [3.0, 2.5, 0.7, 2.25, 0.2, 2.0, 0.25]],\n",
       "  'boundary': <function ssms.basic_simulators.boundary_functions.constant(t=0)>,\n",
       "  'n_params': 7,\n",
       "  'default_params': [0.0, 1.0, 0.5, 0.25, 0.001, 0.001, 0.001],\n",
       "  'hddm_include': ['z', 'st', 'sv', 'sz'],\n",
       "  'nchoices': 2},\n",
       " 'data_config': {'output_folder': 'data/lan_mlp/',\n",
       "  'dgp_list': 'full_ddm',\n",
       "  'nbins': 0,\n",
       "  'n_samples': 200000,\n",
       "  'n_parameter_sets': 1000,\n",
       "  'n_parameter_sets_rejected': 100,\n",
       "  'n_training_samples_by_parameter_set': 2000,\n",
       "  'max_t': 20.0,\n",
       "  'delta_t': 0.001,\n",
       "  'pickleprotocol': 4,\n",
       "  'n_cpus': 'all',\n",
       "  'kde_data_mixture_probabilities': [0.8, 0.1, 0.1],\n",
       "  'simulation_filters': {'mode': 20,\n",
       "   'choice_cnt': 5,\n",
       "   'mean_rt': 15,\n",
       "   'std': 0,\n",
       "   'mode_cnt_rel': 0.6},\n",
       "  'negative_rt_cutoff': -66.77497,\n",
       "  'n_subruns': 5,\n",
       "  'bin_pointwise': False,\n",
       "  'separate_response_channels': False}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify model\n",
    "model = 'full_ddm'\n",
    "\n",
    "# Where do you want to save the config file?\n",
    "config_save_folder = '/users/afengler/data/proj_lan_pipeline/LAN_scripts/config_files/'\n",
    "\n",
    "# What kind of likelihood approximator are we generating training data for?\n",
    "generator_approach = 'lan'\n",
    "\n",
    "# Specific network type we train? (Might affect training data representation needed)\n",
    "generator_network_type = 'mlp'\n",
    "\n",
    "# Specify arguments which you want to adjust in the data generator\n",
    "data_generator_arg_dict = {'dgp_list': model,\n",
    "                           'n_samples': 200000,\n",
    "                           'n_parameter_sets': 1000,\n",
    "                           'delta_t': 0.001,\n",
    "                           'n_training_samples_by_parameter_set': 2000,\n",
    "                           'n_subruns': 5}\n",
    "\n",
    "# model_config_arg_dict = {'param_bounds': [[-2.5, 0.2, 0.1, 0.0],\n",
    "#                                           [2.5, 2.2, 0.9, 2.0]]}\n",
    "model_config_arg_dict = {}\n",
    "\n",
    "# Name of the config file\n",
    "data_config_save_name = model + '_nsim_' + str(data_generator_arg_dict['n_samples']) + \\\n",
    "                        '_dt_' + str(data_generator_arg_dict['delta_t']) + \\\n",
    "                        '_nps_' + str(data_generator_arg_dict['n_parameter_sets']) + \\\n",
    "                        '_npts_' + str(data_generator_arg_dict['n_training_samples_by_parameter_set']) + '.pickle'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce27325-2edf-4d5a-ad7b-bbd598e3f980",
   "metadata": {},
   "source": [
    "### Generate the Config File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c538e456-3069-4e2f-a017-9c06c5f8e4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_data_generator_configs(model = model,\n",
    "                            generator_approach = 'lan',\n",
    "                            generator_network_type = 'mlp',\n",
    "                            data_generator_arg_dict = data_generator_arg_dict,\n",
    "                            model_config_arg_dict = model_config_arg_dict,\n",
    "                            save_name = data_config_save_name,\n",
    "                            save_folder = config_save_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3e579d-1f16-4abb-81fa-9d4252d8ec69",
   "metadata": {},
   "source": [
    "# NETWORK AND TRAIN CONFIGS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f88cbc-3ab9-48f2-813f-0fdbd7de580e",
   "metadata": {},
   "source": [
    "### Define Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b588ae2b-613f-4a75-96ac-608c6954c307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where do you want to save config files?\n",
    "network_train_config_save_folder = '/users/afengler/data/proj_lan_pipeline/LAN_scripts/config_files/'\n",
    "\n",
    "# Specify training data folder:\n",
    "training_data_folder = '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000'\n",
    "\n",
    "# Provide a unique identifier for the particular files you need from the training_data_folder\n",
    "training_file_identifier = 'ddm_mic2_adj_weibull_no_bias'\n",
    "\n",
    "# Specify the name of the config file\n",
    "network_train_config_save_name = hardware + '_' + dl_backend + '_network_train_config_' + training_file_identifier + '_nsim_200000_dt_0.001_nps_500_npts_2000_architecture_search.pickle'\n",
    "\n",
    "# Hardware and dl_backend\n",
    "hardware = 'gpu'\n",
    "dl_backend = 'torch'\n",
    "\n",
    "# Get list of relevant training files\n",
    "file_list = os.listdir(training_data_folder)\n",
    "valid_file_list = np.array([training_data_folder + '/' + \\\n",
    "                     file_ for file_ in file_list if training_file_identifier in file_])\n",
    "n_training_files = [len(valid_file_list)]\n",
    "print(n_training_files)\n",
    "\n",
    "# Training config hyperparameters\n",
    "\n",
    "# Hardware\n",
    "if hardware == 'gpu':\n",
    "    print('config for gpu --> use large batch size')\n",
    "    batch_size = 100000\n",
    "if hardware == 'cpu':\n",
    "    print('config for cpu --> use small batch size')\n",
    "    batch_size = 1000\n",
    "\n",
    "# How many epochs to train?\n",
    "n_epochs = 20\n",
    "\n",
    "# Network architectures\n",
    "layer_sizes = [[100, 100, 100, 1], [100, 100, 100, 100, 1], [100, 100, 100, 100, 100, 1],\n",
    "               [120, 120, 120, 1], [120, 120, 120, 120, 1], [120, 120, 120, 120, 120, 1],\n",
    "               [150, 150, 150, 1], [150, 150, 150, 150, 1], [150, 150, 150, 150, 150, 1]]\n",
    "layer_types = [['dense', 'dense', 'dense', 'dense'], ['dense', 'dense', 'dense', 'dense', 'dense'], ['dense', 'dense', 'dense', 'dense', 'dense', 'dense'],\n",
    "               ['dense', 'dense', 'dense', 'dense'], ['dense', 'dense', 'dense', 'dense', 'dense'], ['dense', 'dense', 'dense', 'dense', 'dense', 'dense'],\n",
    "               ['dense', 'dense', 'dense', 'dense'], ['dense', 'dense', 'dense', 'dense', 'dense'], ['dense', 'dense', 'dense', 'dense', 'dense', 'dense'],\n",
    "              ]\n",
    "activations = [['tanh', 'tanh', 'tanh', 'linear'], ['tanh', 'tanh', 'tanh', 'tanh', 'linear'], ['tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'linear'],\n",
    "               ['tanh', 'tanh', 'tanh', 'linear'], ['tanh', 'tanh', 'tanh', 'tanh', 'linear'], ['tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'linear'],\n",
    "               ['tanh', 'tanh', 'tanh', 'linear'], ['tanh', 'tanh', 'tanh', 'tanh', 'linear'], ['tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'linear'],\n",
    "              ]\n",
    "\n",
    "# Train / validations split\n",
    "train_val_split = [0.98, 0.98, 0.98, \n",
    "                   0.98, 0.98, 0.98,\n",
    "                   0.98, 0.98, 0.98]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7d0407-aa53-40e5-b2db-f7535cd6117a",
   "metadata": {},
   "source": [
    "### Create the Config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d1bd45b-1d18-4df8-8f59-bfc49ffebe43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\n",
      "NEW PRINT\n",
      "0\n",
      "NEW PRINT\n",
      "1\n",
      "NEW PRINT\n",
      "2\n",
      "NEW PRINT\n",
      "3\n",
      "NEW PRINT\n",
      "4\n",
      "NEW PRINT\n",
      "5\n",
      "NEW PRINT\n",
      "6\n",
      "NEW PRINT\n",
      "7\n",
      "NEW PRINT\n",
      "8\n",
      "Now saving\n"
     ]
    }
   ],
   "source": [
    "# Loop objects\n",
    "config_dict = {}\n",
    "network_arg_dicts = {}\n",
    "train_arg_dicts = {}    \n",
    "cnt = 0\n",
    "\n",
    "for i in range(len(layer_sizes)):\n",
    "    for j in range(len(n_training_files)):\n",
    "        val_idx_cutoff = int(train_val_split[i] * n_training_files[j])\n",
    "\n",
    "        # Specify the arguments which you want to adjust in the network and train configs\n",
    "        # Check: lanfactory.config.network_config_mlp\n",
    "        #        lanfactor.config.train_config_mlp for details\n",
    "\n",
    "        network_arg_dict = {'layer_types': layer_types[i],\n",
    "                            'layer_sizes': layer_sizes[i],\n",
    "                            'activations': activations[i],\n",
    "                            'loss': ['huber'],\n",
    "                            'model_id': training_file_identifier\n",
    "                            }\n",
    "\n",
    "        train_arg_dict = {'batch_size': batch_size,\n",
    "                          'n_epochs': n_epochs,\n",
    "                          'training_files': valid_file_list[:val_idx_cutoff],\n",
    "                          'validation_files': valid_file_list[val_idx_cutoff:n_training_files[j]],\n",
    "                          'shuffle_files': True,\n",
    "                          'label_prelog_cutoff_low': 1e-7,\n",
    "                          'label_prelog_cutoff_high': None,\n",
    "                          'save_history': True,\n",
    "                          'callbacks': ['checkpoint', 'earlystopping', 'reducelr'],\n",
    "                          }\n",
    "\n",
    "        config_dict[cnt] = make_train_network_configs(save_folder = network_train_config_save_folder,\n",
    "                                                      network_arg_dict = network_arg_dict,\n",
    "                                                      train_arg_dict = train_arg_dict,\n",
    "                                                      save_name = None)\n",
    "        \n",
    "        print('NEW PRINT')\n",
    "        print(cnt)\n",
    "        cnt += 1\n",
    "\n",
    "print('Now saving')\n",
    "pickle.dump(config_dict, open(network_train_config_save_folder + network_train_config_save_name, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f7d1af0-a2fa-4da3-878e-35edb3a4f292",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pickle.load(open(network_train_config_save_folder + network_train_config_save_name, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "977f007d-47e2-4f29-9850-de862e8d4b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'network_config': {'layer_types': ['dense', 'dense', 'dense'],\n",
       "  'layer_sizes': [100, 100, 1],\n",
       "  'activations': ['tanh', 'tanh', 'linear'],\n",
       "  'loss': ['huber'],\n",
       "  'callbacks': ['checkpoint', 'earlystopping', 'reducelr'],\n",
       "  'model_id': 'race_no_bias_4'},\n",
       " 'train_config': {'batch_size': 50000,\n",
       "  'n_epochs': 200,\n",
       "  'optimizer': 'adam',\n",
       "  'learning_rate': 0.002,\n",
       "  'loss': 'huber',\n",
       "  'metrics': [<tensorflow.python.keras.losses.MeanSquaredError at 0x7fafc1ae55d0>,\n",
       "   <tensorflow.python.keras.losses.Huber at 0x7fb3f13ad850>],\n",
       "  'callbacks': ['checkpoint', 'earlystopping', 'reducelr'],\n",
       "  'training_files': array(['/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_9353d924fc6311eb95df0cc47afdbf59.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_3843ab7afbcf11eba97d0cc47afdbfb9.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_744c6890fbee11ebb8660cc47afdbf9b.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_40419844fc2111ebad42ac1f6b627e8e.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_4406dfc6fbee11ebad90ac1f6bb0474c.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_06f40d72fc2811eb8cd5ac1f6b1b7bac.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_f1371466fbe111eba80fac1f6b627d6e.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_5a964b3efc6911ebaa14ac1f6b627e8e.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_a056279afc1211eb8f3aac1f6b1b7b16.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_14b20b24fc2011eb8cfeac1f6b63e9c0.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_3550d57afc7c11ebb6900cc47afdbf59.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_8548c67efc7b11eb8a22ac1f6b63e9c0.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_36b1b4befc6511eb89afac1f6b1b7976.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_dbdc7d4afc4011eb9c72ac1f6bb047d8.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_76ae5e86fc5711eb9b74ac1f6b63e7a0.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_086e4150fc4a11eb8a490cc47afdc014.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_510f89d0fc6f11eb955dac1f6b63e82e.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_5d2c5fc4fbf511ebbb9dac1f6b1b7bac.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_20a11c0afbe811eba2ddac1f6b63e9de.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_7e009c86fc3811ebae81ac1f6b1b7b16.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_fcdec6d2fbe711eb900b0cc47afdbf9b.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_e5ff1366fc2511ebbaadac1f6b627d2c.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_4297b47efbfa11ebb71eac1f6b1b7a88.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_0311597cfc2c11ebb33fac1f6b63e676.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_1a11ce90fbc311ebb8f8ac1f6bb046cc.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_5e0a0f88fc0711eb8373ac1f6b1b7994.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_cfce655cfbd411eb9fc5ac1f6b63e9de.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_10b2aa6cfc1411eb935a0cc47afdbfb9.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_a0d59df0fc0c11eba5f2ac1f6b1b7976.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_1589fb56fc6b11eb9f53ac1f6b1b7994.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_b7f6d0b2fc5711ebb945ac1f6b1b78f2.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_cd78c054fc6a11eb830c0cc47afdbf3c.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_e624bab0fc6d11eb8fa7ac1f6b1b7bb8.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_f542e258fc5c11eb8fbeac1f6b63e9c0.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_2cf428e6fbc311eb940eac1f6bb047c8.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_5bc5b332fbe711eb833fac1f6b1b78cc.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_cf61a004fc0e11ebb588ac1f6b63e9f4.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_9ab95b4efbe111ebaf560cc47afdc01b.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_376ca92efc7711eba365ac1f6b627e86.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_070510f8fc6f11ebbff4ac1f6b63e9c0.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_a8a70c70fc5d11ebb070ac1f6b63e7a0.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_fa556de0fbe111ebb55cac1f6b1b7afc.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_44178c6efbed11ebbba4ac1f6bb2faa0.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_a901295afc1f11eba0e5ac1f6b63e9c0.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_ffed4652fbf411ebbb190cc47afdbfb9.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_a151eb98fbdb11eba1ce0cc47afdbf9b.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_4b920c90fc1911eba0b3ac1f6b1b7b60.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_da1f8ca2fc0111ebbf96ac1f6b1b7bac.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_2ad3bf30fbe711ebabe1ac1f6bb2faa0.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_7c60a59efbe111eb868dac1f6b63e676.pickle'],\n",
       "        dtype='<U165'),\n",
       "  'validation_files': array(['/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_a151eb98fbdb11eba1ce0cc47afdbf9b.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_4b920c90fc1911eba0b3ac1f6b1b7b60.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_da1f8ca2fc0111ebbf96ac1f6b1b7bac.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_2ad3bf30fbe711ebabe1ac1f6bb2faa0.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_race_no_bias_4_7c60a59efbe111eb868dac1f6b63e676.pickle'],\n",
       "        dtype='<U165'),\n",
       "  'shuffle_files': True,\n",
       "  'label_prelog_cutoff_low': 1e-07,\n",
       "  'label_prelog_cutoff_high': None,\n",
       "  'save_history': True}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lanfactory",
   "language": "python",
   "name": "lanfactory"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
