{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be7b9564-be61-46d4-9e86-8cc013f99654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing lanfactory\n",
      "importing ssms\n",
      "importing lanfactory\n",
      "importing ssms\n"
     ]
    }
   ],
   "source": [
    "# Append system path to include the config scripts\n",
    "import sys\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "\n",
    "print('importing lanfactory')\n",
    "import lanfactory\n",
    "\n",
    "print('importing ssms')\n",
    "import ssms\n",
    "\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "from config import *\n",
    "\n",
    "import torch\n",
    "import config\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09fa27e8-98c2-4b9a-aace-e8dab0aab2d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ddm', 'ddm_legacy', 'ddm_deadline', 'angle', 'weibull', 'levy', 'levy_angle', 'full_ddm', 'gamma_drift', 'gamma_drift_angle', 'ds_conflict_drift', 'ds_conflict_drift_angle', 'ornstein', 'ornstein_angle', 'ddm_sdv', 'race_3', 'race_no_bias_3', 'race_no_bias_angle_3', 'race_4', 'race_no_bias_4', 'race_no_bias_angle_4', 'lca_3', 'lca_no_bias_3', 'lca_no_bias_angle_3', 'lca_4', 'lca_no_bias_4', 'lca_no_bias_angle_4', 'ddm_par2', 'ddm_par2_no_bias', 'ddm_par2_conflict_gamma_no_bias', 'ddm_par2_angle_no_bias', 'ddm_par2_weibull_no_bias', 'ddm_seq2', 'ddm_seq2_no_bias', 'ddm_seq2_conflict_gamma_no_bias', 'ddm_seq2_angle_no_bias', 'ddm_seq2_weibull_no_bias', 'ddm_mic2_adj', 'ddm_mic2_adj_no_bias', 'ddm_mic2_adj_conflict_gamma_no_bias', 'ddm_mic2_adj_angle_no_bias', 'ddm_mic2_adj_weibull_no_bias', 'tradeoff_no_bias', 'tradeoff_angle_no_bias', 'tradeoff_weibull_no_bias', 'tradeoff_conflict_gamma_no_bias', 'glob', 'weibull_cdf', 'full_ddm2'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssms.config.model_config.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa9cfcf-8457-457b-8d83-4cd25f857bcc",
   "metadata": {},
   "source": [
    "# DATA GENERATOR CONFIGS\n",
    "\n",
    "**Note:** Look into the ssms package documentation to get a better idea about the kinds of configs that you need for different kinds of training data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe715a1c-fcef-4223-901a-5866ffa35039",
   "metadata": {},
   "source": [
    "### Define Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c39eb60-efb9-4249-b7e8-4c8bd82bc6f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify model\n",
    "MODEL = 'ddm' #'ddm_deadline' # 'ds_conflict_drift'\n",
    "\n",
    "# Specify data_generator parameters\n",
    "N_SAMPLES = 20000 #200000\n",
    "N_PARAMETER_SETS = 1000 #5000\n",
    "DELTA_T = 0.001\n",
    "N_TRAINING_SAMPLES_BY_PARAMETER_SET = 2000\n",
    "N_SUBRUNS = 20\n",
    "CPN_ONLY = False # if true simulator will run faster but produce only choice probabilities\n",
    "\n",
    "# proj folder\n",
    "PROJECT_FOLDER = '/users/afengler/data/proj_lan_pipeline/LAN_scripts/'\n",
    "\n",
    "# What kind of likelihood approximator are we generating training data for?\n",
    "GENERATOR_APPROACH = 'lan' if CPN_ONLY is False else 'cpn_only'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3407e4-83a4-40be-8b66-d3eeac08447d",
   "metadata": {},
   "source": [
    "### Use Metadata to specify arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3e843d7-5682-402e-b393-d7ae9fbe09a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data folder\n",
    "training_data_folder = PROJECT_FOLDER + \\\n",
    "                         '/data/training_data/' + GENERATOR_APPROACH + \\\n",
    "                            '/training_data_n_samples' + '_' + \\\n",
    "                                str(N_SAMPLES) + '/' + MODEL + '/'\n",
    "\n",
    "# Where do you want to save the config file?\n",
    "config_save_folder = PROJECT_FOLDER + '/data/config_files/data_generation/' + \\\n",
    "                        GENERATOR_APPROACH + '/' + MODEL + '/'\n",
    "\n",
    "# Specify arguments which you want to adjust in the data generator\n",
    "data_generator_arg_dict = {\n",
    "                           'output_folder': training_data_folder,\n",
    "                           'dgp_list': MODEL,\n",
    "                           'n_samples': N_SAMPLES,\n",
    "                           'n_parameter_sets': N_PARAMETER_SETS,\n",
    "                           'delta_t': DELTA_T,\n",
    "                           'n_training_samples_by_parameter_set': N_TRAINING_SAMPLES_BY_PARAMETER_SET,\n",
    "                           'n_subruns': N_SUBRUNS,\n",
    "                           'cpn_only': True if GENERATOR_APPROACH == \"cpn_only\" else False,\n",
    "                          }\n",
    "\n",
    "# model_config_arg_dict = {'param_bounds': [[-2.5, 0.2, 0.1, 0.0],\n",
    "#                                           [2.5, 2.2, 0.9, 2.0]]}\n",
    "model_config_arg_dict = {}\n",
    "\n",
    "# Name of the config file\n",
    "data_config_save_name = 'nsim_' + str(data_generator_arg_dict['n_samples']) + \\\n",
    "                        '_dt_' + str(data_generator_arg_dict['delta_t']) + \\\n",
    "                        '_nps_' + str(data_generator_arg_dict['n_parameter_sets']) + \\\n",
    "                        '_npts_' + str(data_generator_arg_dict['n_training_samples_by_parameter_set']) + \\\n",
    "                        '.pickle'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce27325-2edf-4d5a-ad7b-bbd598e3f980",
   "metadata": {},
   "source": [
    "### Generate the Config File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c538e456-3069-4e2f-a017-9c06c5f8e4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found folder:  /users\n",
      "Moving on...\n",
      "Found folder:  /users/afengler\n",
      "Moving on...\n",
      "Found folder:  /users/afengler/data\n",
      "Moving on...\n",
      "Found folder:  /users/afengler/data/proj_lan_pipeline\n",
      "Moving on...\n",
      "Found folder:  /users/afengler/data/proj_lan_pipeline/LAN_scripts\n",
      "Moving on...\n",
      "Found folder:  /users/afengler/data/proj_lan_pipeline/LAN_scripts/data\n",
      "Moving on...\n",
      "Found folder:  /users/afengler/data/proj_lan_pipeline/LAN_scripts/data/config_files\n",
      "Moving on...\n",
      "Found folder:  /users/afengler/data/proj_lan_pipeline/LAN_scripts/data/config_files/data_generation\n",
      "Moving on...\n",
      "Found folder:  /users/afengler/data/proj_lan_pipeline/LAN_scripts/data/config_files/data_generation/lan\n",
      "Moving on...\n",
      "Found folder:  /users/afengler/data/proj_lan_pipeline/LAN_scripts/data/config_files/data_generation/lan/ddm\n",
      "Moving on...\n",
      "Saved to: \n",
      "/users/afengler/data/proj_lan_pipeline/LAN_scripts//data/config_files/data_generation/lan/ddm/nsim_20000_dt_0.001_nps_1000_npts_2000.pickle\n"
     ]
    }
   ],
   "source": [
    "data_config_dict = make_data_generator_configs(model = MODEL,\n",
    "                                               generator_approach = GENERATOR_APPROACH,\n",
    "                                               data_generator_arg_dict = data_generator_arg_dict,\n",
    "                                               model_config_arg_dict = model_config_arg_dict,\n",
    "                                               save_name = data_config_save_name,\n",
    "                                               save_folder = config_save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e56029b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'config_dict': {'model_config': {'name': 'ddm',\n",
       "   'params': ['v', 'a', 'z', 't'],\n",
       "   'param_bounds': [[-3.0, 0.3, 0.1, 0.0], [3.0, 2.5, 0.9, 2.0]],\n",
       "   'boundary': <function ssms.basic_simulators.boundary_functions.constant(t=0)>,\n",
       "   'n_params': 4,\n",
       "   'default_params': [0.0, 1.0, 0.5, 0.001],\n",
       "   'hddm_include': ['z'],\n",
       "   'nchoices': 2},\n",
       "  'data_config': {'output_folder': '/users/afengler/data/proj_lan_pipeline/LAN_scripts//data/training_data/cpn_only/training_data_n_samples_20000/ddm/',\n",
       "   'dgp_list': 'ddm',\n",
       "   'n_samples': 20000,\n",
       "   'n_parameter_sets': 1000,\n",
       "   'n_parameter_sets_rejected': 100,\n",
       "   'n_training_samples_by_parameter_set': 2000,\n",
       "   'max_t': 20.0,\n",
       "   'delta_t': 0.001,\n",
       "   'pickleprotocol': 4,\n",
       "   'n_cpus': 'all',\n",
       "   'negative_rt_cutoff': -66.77497,\n",
       "   'n_subruns': 20,\n",
       "   'cpn_only': True}},\n",
       " 'config_file_name': '/users/afengler/data/proj_lan_pipeline/LAN_scripts//data/config_files/data_generation/cpn_only/ddm/nsim_20000_dt_0.001_nps_1000_npts_2000.pickle'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_config_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3e579d-1f16-4abb-81fa-9d4252d8ec69",
   "metadata": {},
   "source": [
    "# NETWORK AND TRAIN CONFIGS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f88cbc-3ab9-48f2-813f-0fdbd7de580e",
   "metadata": {},
   "source": [
    "### Define Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b588ae2b-613f-4a75-96ac-608c6954c307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# network type\n",
    "NETWORK_TYPE = 'cpn' # lan, choicep\n",
    "\n",
    "CPU_BATCH_SIZE = 128 # lan: 1000, cpn: 128\n",
    "GPU_BATCH_SIZE = 512 # lan: 50000, cpn: 1024\n",
    "\n",
    "# what kind of training data ?\n",
    "GENERATOR_APPROACH = 'lan'\n",
    "\n",
    "# optimizer\n",
    "OPTIMIZER_ = 'adam' # 'adam', 'sgd'\n",
    "\n",
    "# How many epochs to train?\n",
    "N_EPOCHS = 20 # lan: 20, cpn: 50\n",
    "\n",
    "# Where do you want to save config files?\n",
    "network_train_config_save_folder = PROJECT_FOLDER + '/data/config_files/network/' + \\\n",
    "                                       NETWORK_TYPE + '/' + MODEL + '/'\n",
    "\n",
    "\n",
    "\n",
    "# Specify training data folder:\n",
    "training_data_folder = PROJECT_FOLDER + \\\n",
    "                           '/data/training_data/' + GENERATOR_APPROACH + '/' + \\\n",
    "                               'training_data_n_samples' +  \\\n",
    "                                '_' + str(N_SAMPLES) + '/' + MODEL\n",
    "\n",
    "# Specify the name of the config file\n",
    "network_train_config_save_name = 'train_config' + \\\n",
    "                                     '_opt_' + OPTIMIZER_ + \\\n",
    "                                        '_n_' + str(N_SAMPLES) + \\\n",
    "                                            '_dt_' + str(DELTA_T) + \\\n",
    "                                                '_nps_' + str(N_PARAMETER_SETS) + \\\n",
    "                                                    '_npts_' + str(N_TRAINING_SAMPLES_BY_PARAMETER_SET) + \\\n",
    "                                                        '_architecture_search.pickle'\n",
    "\n",
    "\n",
    "\n",
    "# Loss\n",
    "\n",
    "# 'bce', use when train output is 'prob'\n",
    "# 'bcelogit' use when train output type is 'logits', \n",
    "# 'mse'\n",
    "# 'huber' (usually) used when train output is 'logprob'\n",
    "#loss = 'huber' \n",
    "\n",
    "# output \n",
    "#train_output_type = 'logprob' # logprob, logits, prob\n",
    "\n",
    "train_output_type_dict = {'lan': 'logprob',\n",
    "                          'cpn': 'logits',\n",
    "                          'cpn_bce': 'prob',\n",
    "                         }\n",
    "\n",
    "output_layer_dict = {'logits': 'linear',\n",
    "                     'logprob': 'linear',\n",
    "                     'prob': 'sigmoid'}\n",
    "\n",
    "train_loss_dict = {'logprob': 'huber',\n",
    "                   'logits': 'bcelogit',\n",
    "                   'prob': 'bce'}\n",
    "\n",
    "# Network architectures\n",
    "layer_sizes = [[100, 100, 100, 1], [100, 100, 100, 100, 1], [100, 100, 100, 100, 100, 1],\n",
    "               [120, 120, 120, 1], [120, 120, 120, 120, 1], [120, 120, 120, 120, 120, 1]] #,\n",
    "#                [150, 150, 150, 1], [150, 150, 150, 150, 1], [150, 150, 150, 150, 150, 1]]\n",
    "\n",
    "activations = [['tanh', 'tanh', 'tanh', output_layer_dict[train_output_type_dict[NETWORK_TYPE]]], \n",
    "               ['tanh', 'tanh', 'tanh', 'tanh', output_layer_dict[train_output_type_dict[NETWORK_TYPE]]], \n",
    "               ['tanh', 'tanh', 'tanh', 'tanh', 'tanh', output_layer_dict[train_output_type_dict[NETWORK_TYPE]]],\n",
    "               ['tanh', 'tanh', 'tanh', output_layer_dict[train_output_type_dict[NETWORK_TYPE]]], \n",
    "               ['tanh', 'tanh', 'tanh', 'tanh', output_layer_dict[train_output_type_dict[NETWORK_TYPE]]], \n",
    "               ['tanh', 'tanh', 'tanh', 'tanh', 'tanh', output_layer_dict[train_output_type_dict[NETWORK_TYPE]]]\n",
    "              ]\n",
    "\n",
    "weight_decays = [0.0]\n",
    "\n",
    "# Train / validations split\n",
    "train_val_split = [0.98, 0.98, 0.98,\n",
    "                   0.98, 0.98, 0.98]\n",
    "\n",
    "# \n",
    "n_training_files = [10000]\n",
    "\n",
    "# \n",
    "network_arg_dict = {'train_output_type': train_output_type_dict[NETWORK_TYPE],\n",
    "                    'network_type': NETWORK_TYPE}\n",
    "\n",
    "\n",
    "data_key_dict = {'lan': {'features_key': 'data', \n",
    "                         'label_key': 'labels'},\n",
    "                 'cpn': {'features_key': 'thetas',\n",
    "                         'label_key': 'choice_p'}\n",
    "                }\n",
    "\n",
    "# initial train_arg_dict\n",
    "# refined in for loop in next cell\n",
    "train_arg_dict = {'n_epochs': N_EPOCHS,\n",
    "                  'loss': train_loss_dict[train_output_type_dict[NETWORK_TYPE]],\n",
    "                  'optimizer': OPTIMIZER_,\n",
    "                  'train_output_type': train_output_type_dict[NETWORK_TYPE],\n",
    "                  # 'n_training_files': n_training_files[j],\n",
    "                  # 'train_val_split': train_val_split[i],\n",
    "                  'cpu_batch_size': CPU_BATCH_SIZE,\n",
    "                  'gpu_batch_size': GPU_BATCH_SIZE,\n",
    "                  'shuffle_files': True,\n",
    "                  'label_lower_bound': np.log(1e-7),\n",
    "                  # 'weight_decay': weight_decays[k],\n",
    "                  'learning_rate': 0.001,\n",
    "                  'features_key': data_key_dict[NETWORK_TYPE]['features_key'],\n",
    "                  'label_key': data_key_dict[NETWORK_TYPE]['label_key'],\n",
    "                  'save_history': True,\n",
    "                  'lr_scheduler': 'reduce_on_plateau',\n",
    "                  'lr_scheduler_params': {'factor': 0.1,\n",
    "                                          'patience': 2,\n",
    "                                          'threshold': 0.001,\n",
    "                                          'min_lr': 0.00000001,\n",
    "                                          'verbose': True,\n",
    "                                         }\n",
    "                  }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7d0407-aa53-40e5-b2db-f7535cd6117a",
   "metadata": {},
   "source": [
    "### Create the Config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d1bd45b-1d18-4df8-8f59-bfc49ffebe43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total,  6  different networks will be trained with this config file\n",
      "Now saving\n",
      "Found folder:  /users\n",
      "Moving on...\n",
      "Found folder:  /users/afengler\n",
      "Moving on...\n",
      "Found folder:  /users/afengler/data\n",
      "Moving on...\n",
      "Found folder:  /users/afengler/data/proj_lan_pipeline\n",
      "Moving on...\n",
      "Found folder:  /users/afengler/data/proj_lan_pipeline/LAN_scripts\n",
      "Moving on...\n",
      "Found folder:  /users/afengler/data/proj_lan_pipeline/LAN_scripts/data\n",
      "Moving on...\n",
      "Found folder:  /users/afengler/data/proj_lan_pipeline/LAN_scripts/data/config_files\n",
      "Moving on...\n",
      "Found folder:  /users/afengler/data/proj_lan_pipeline/LAN_scripts/data/config_files/network\n",
      "Moving on...\n",
      "Found folder:  /users/afengler/data/proj_lan_pipeline/LAN_scripts/data/config_files/network/cpn\n",
      "Moving on...\n",
      "Found folder:  /users/afengler/data/proj_lan_pipeline/LAN_scripts/data/config_files/network/cpn/ddm\n",
      "Moving on...\n",
      "/users/afengler/data/proj_lan_pipeline/LAN_scripts//data/config_files/network/cpn/ddm/train_config_opt_adam_n_20000_dt_0.001_nps_1000_npts_2000_architecture_search.pickle\n"
     ]
    }
   ],
   "source": [
    "# Loop objects\n",
    "config_dict = {}\n",
    "network_arg_dicts = {}\n",
    "train_arg_dicts = {}\n",
    "\n",
    "cnt = 0\n",
    "for k in range(len(weight_decays)):\n",
    "    for i in range(len(layer_sizes)):\n",
    "        for j in range(len(n_training_files)):\n",
    "            \n",
    "            # Specify the arguments which you want to adjust in the network and train configs\n",
    "            # For details check: lanfactory.config.network_config_mlp\n",
    "            #                    lanfactory.config.train_config_mlp\n",
    "\n",
    "            network_arg_dict['layer_sizes'] = layer_sizes[i]\n",
    "            network_arg_dict['activations'] = activations[i]\n",
    "            \n",
    "            train_arg_dict['n_training_files'] = n_training_files[j]\n",
    "            train_arg_dict['train_val_split'] = train_val_split[i]\n",
    "            train_arg_dict['weight_decay'] = weight_decays[k]\n",
    "\n",
    "            config_dict[cnt] = make_train_network_configs(training_data_folder=training_data_folder,\n",
    "                                                          save_folder = network_train_config_save_folder,\n",
    "                                                          train_val_split=train_val_split[i],\n",
    "                                                          network_arg_dict = deepcopy(network_arg_dict),\n",
    "                                                          train_arg_dict = deepcopy(train_arg_dict),\n",
    "                                                          save_name = None)\n",
    "\n",
    "            cnt += 1\n",
    "\n",
    "print('In total, ',\n",
    "          len(list(config_dict.keys())),\n",
    "              ' different networks will be trained with this config file')\n",
    "\n",
    "print('Now saving')\n",
    "\n",
    "# Create save_folder if not already there\n",
    "lanfactory.utils.try_gen_folder(folder = network_train_config_save_folder,\n",
    "                                allow_abs_path_folder_generation = True)\n",
    "                \n",
    "pickle.dump(config_dict, \n",
    "            open(network_train_config_save_folder + network_train_config_save_name, 'wb'))\n",
    "print(network_train_config_save_folder + network_train_config_save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22268d98-a711-431d-93a4-1b872da863a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'config_dict': {'network_config': {'layer_sizes': [100, 100, 100, 1],\n",
       "    'activations': ['tanh', 'tanh', 'tanh', 'linear'],\n",
       "    'train_output_type': 'logits',\n",
       "    'network_type': 'cpn'},\n",
       "   'train_config': {'cpu_batch_size': 128,\n",
       "    'gpu_batch_size': 512,\n",
       "    'n_epochs': 20,\n",
       "    'optimizer': 'adam',\n",
       "    'learning_rate': 0.001,\n",
       "    'lr_scheduler': 'reduce_on_plateau',\n",
       "    'lr_scheduler_params': {'factor': 0.1,\n",
       "     'patience': 2,\n",
       "     'threshold': 0.001,\n",
       "     'min_lr': 1e-08,\n",
       "     'verbose': True},\n",
       "    'weight_decay': 0.0,\n",
       "    'loss': 'bcelogit',\n",
       "    'save_history': True,\n",
       "    'train_output_type': 'logits',\n",
       "    'shuffle_files': True,\n",
       "    'label_lower_bound': -16.11809565095832,\n",
       "    'features_key': 'thetas',\n",
       "    'label_key': 'choice_p',\n",
       "    'n_training_files': 10000,\n",
       "    'train_val_split': 0.98},\n",
       "   'training_data_folder': '/users/afengler/data/proj_lan_pipeline/LAN_scripts//data/training_data/lan/training_data_n_samples_20000/ddm',\n",
       "   'train_val_split': 0.98},\n",
       "  'config_file_name': None},\n",
       " 1: {'config_dict': {'network_config': {'layer_sizes': [100, 100, 100, 100, 1],\n",
       "    'activations': ['tanh', 'tanh', 'tanh', 'tanh', 'linear'],\n",
       "    'train_output_type': 'logits',\n",
       "    'network_type': 'cpn'},\n",
       "   'train_config': {'cpu_batch_size': 128,\n",
       "    'gpu_batch_size': 512,\n",
       "    'n_epochs': 20,\n",
       "    'optimizer': 'adam',\n",
       "    'learning_rate': 0.001,\n",
       "    'lr_scheduler': 'reduce_on_plateau',\n",
       "    'lr_scheduler_params': {'factor': 0.1,\n",
       "     'patience': 2,\n",
       "     'threshold': 0.001,\n",
       "     'min_lr': 1e-08,\n",
       "     'verbose': True},\n",
       "    'weight_decay': 0.0,\n",
       "    'loss': 'bcelogit',\n",
       "    'save_history': True,\n",
       "    'train_output_type': 'logits',\n",
       "    'shuffle_files': True,\n",
       "    'label_lower_bound': -16.11809565095832,\n",
       "    'features_key': 'thetas',\n",
       "    'label_key': 'choice_p',\n",
       "    'n_training_files': 10000,\n",
       "    'train_val_split': 0.98},\n",
       "   'training_data_folder': '/users/afengler/data/proj_lan_pipeline/LAN_scripts//data/training_data/lan/training_data_n_samples_20000/ddm',\n",
       "   'train_val_split': 0.98},\n",
       "  'config_file_name': None},\n",
       " 2: {'config_dict': {'network_config': {'layer_sizes': [100,\n",
       "     100,\n",
       "     100,\n",
       "     100,\n",
       "     100,\n",
       "     1],\n",
       "    'activations': ['tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'linear'],\n",
       "    'train_output_type': 'logits',\n",
       "    'network_type': 'cpn'},\n",
       "   'train_config': {'cpu_batch_size': 128,\n",
       "    'gpu_batch_size': 512,\n",
       "    'n_epochs': 20,\n",
       "    'optimizer': 'adam',\n",
       "    'learning_rate': 0.001,\n",
       "    'lr_scheduler': 'reduce_on_plateau',\n",
       "    'lr_scheduler_params': {'factor': 0.1,\n",
       "     'patience': 2,\n",
       "     'threshold': 0.001,\n",
       "     'min_lr': 1e-08,\n",
       "     'verbose': True},\n",
       "    'weight_decay': 0.0,\n",
       "    'loss': 'bcelogit',\n",
       "    'save_history': True,\n",
       "    'train_output_type': 'logits',\n",
       "    'shuffle_files': True,\n",
       "    'label_lower_bound': -16.11809565095832,\n",
       "    'features_key': 'thetas',\n",
       "    'label_key': 'choice_p',\n",
       "    'n_training_files': 10000,\n",
       "    'train_val_split': 0.98},\n",
       "   'training_data_folder': '/users/afengler/data/proj_lan_pipeline/LAN_scripts//data/training_data/lan/training_data_n_samples_20000/ddm',\n",
       "   'train_val_split': 0.98},\n",
       "  'config_file_name': None},\n",
       " 3: {'config_dict': {'network_config': {'layer_sizes': [120, 120, 120, 1],\n",
       "    'activations': ['tanh', 'tanh', 'tanh', 'linear'],\n",
       "    'train_output_type': 'logits',\n",
       "    'network_type': 'cpn'},\n",
       "   'train_config': {'cpu_batch_size': 128,\n",
       "    'gpu_batch_size': 512,\n",
       "    'n_epochs': 20,\n",
       "    'optimizer': 'adam',\n",
       "    'learning_rate': 0.001,\n",
       "    'lr_scheduler': 'reduce_on_plateau',\n",
       "    'lr_scheduler_params': {'factor': 0.1,\n",
       "     'patience': 2,\n",
       "     'threshold': 0.001,\n",
       "     'min_lr': 1e-08,\n",
       "     'verbose': True},\n",
       "    'weight_decay': 0.0,\n",
       "    'loss': 'bcelogit',\n",
       "    'save_history': True,\n",
       "    'train_output_type': 'logits',\n",
       "    'shuffle_files': True,\n",
       "    'label_lower_bound': -16.11809565095832,\n",
       "    'features_key': 'thetas',\n",
       "    'label_key': 'choice_p',\n",
       "    'n_training_files': 10000,\n",
       "    'train_val_split': 0.98},\n",
       "   'training_data_folder': '/users/afengler/data/proj_lan_pipeline/LAN_scripts//data/training_data/lan/training_data_n_samples_20000/ddm',\n",
       "   'train_val_split': 0.98},\n",
       "  'config_file_name': None},\n",
       " 4: {'config_dict': {'network_config': {'layer_sizes': [120, 120, 120, 120, 1],\n",
       "    'activations': ['tanh', 'tanh', 'tanh', 'tanh', 'linear'],\n",
       "    'train_output_type': 'logits',\n",
       "    'network_type': 'cpn'},\n",
       "   'train_config': {'cpu_batch_size': 128,\n",
       "    'gpu_batch_size': 512,\n",
       "    'n_epochs': 20,\n",
       "    'optimizer': 'adam',\n",
       "    'learning_rate': 0.001,\n",
       "    'lr_scheduler': 'reduce_on_plateau',\n",
       "    'lr_scheduler_params': {'factor': 0.1,\n",
       "     'patience': 2,\n",
       "     'threshold': 0.001,\n",
       "     'min_lr': 1e-08,\n",
       "     'verbose': True},\n",
       "    'weight_decay': 0.0,\n",
       "    'loss': 'bcelogit',\n",
       "    'save_history': True,\n",
       "    'train_output_type': 'logits',\n",
       "    'shuffle_files': True,\n",
       "    'label_lower_bound': -16.11809565095832,\n",
       "    'features_key': 'thetas',\n",
       "    'label_key': 'choice_p',\n",
       "    'n_training_files': 10000,\n",
       "    'train_val_split': 0.98},\n",
       "   'training_data_folder': '/users/afengler/data/proj_lan_pipeline/LAN_scripts//data/training_data/lan/training_data_n_samples_20000/ddm',\n",
       "   'train_val_split': 0.98},\n",
       "  'config_file_name': None},\n",
       " 5: {'config_dict': {'network_config': {'layer_sizes': [120,\n",
       "     120,\n",
       "     120,\n",
       "     120,\n",
       "     120,\n",
       "     1],\n",
       "    'activations': ['tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'linear'],\n",
       "    'train_output_type': 'logits',\n",
       "    'network_type': 'cpn'},\n",
       "   'train_config': {'cpu_batch_size': 128,\n",
       "    'gpu_batch_size': 512,\n",
       "    'n_epochs': 20,\n",
       "    'optimizer': 'adam',\n",
       "    'learning_rate': 0.001,\n",
       "    'lr_scheduler': 'reduce_on_plateau',\n",
       "    'lr_scheduler_params': {'factor': 0.1,\n",
       "     'patience': 2,\n",
       "     'threshold': 0.001,\n",
       "     'min_lr': 1e-08,\n",
       "     'verbose': True},\n",
       "    'weight_decay': 0.0,\n",
       "    'loss': 'bcelogit',\n",
       "    'save_history': True,\n",
       "    'train_output_type': 'logits',\n",
       "    'shuffle_files': True,\n",
       "    'label_lower_bound': -16.11809565095832,\n",
       "    'features_key': 'thetas',\n",
       "    'label_key': 'choice_p',\n",
       "    'n_training_files': 10000,\n",
       "    'train_val_split': 0.98},\n",
       "   'training_data_folder': '/users/afengler/data/proj_lan_pipeline/LAN_scripts//data/training_data/lan/training_data_n_samples_20000/ddm',\n",
       "   'train_val_split': 0.98},\n",
       "  'config_file_name': None}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f7d1af0-a2fa-4da3-878e-35edb3a4f292",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pickle.load(open(network_train_config_save_folder + network_train_config_save_name, 'rb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lan_pipe",
   "language": "python",
   "name": "lan_pipe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
