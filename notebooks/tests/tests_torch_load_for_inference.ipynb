{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "a9b9d212-5fa7-4b88-b57d-ce2957e5a586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import pickle\n",
    "import gzip\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import math\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ee3dc35d-8311-43e9-8ee2-b752ed879887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc_in): Linear(in_features=6, out_features=100, bias=True)\n",
      "  (fc_hidden1): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fc_hidden2): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fc_out): Linear(in_features=100, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc_in = nn.Linear(6, 100)\n",
    "        self.fc_hidden1 = nn.Linear(100, 100)\n",
    "        self.fc_hidden2 = nn.Linear(100, 100)\n",
    "        self.fc_out = nn.Linear(100, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.fc_in(x))\n",
    "        x = F.tanh(self.fc_hidden1(x))\n",
    "        x = F.tanh(self.fc_hidden2(x))\n",
    "        x = self.fc_out(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bb1b4d7a-3519-418e-8e84-34d509a1592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "421288a6-a1ee-4d5f-8515-62844c2fe893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc_in): Linear(in_features=6, out_features=100, bias=True)\n",
       "  (fc_hidden1): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (fc_hidden2): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (fc_out): Linear(in_features=100, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify a path\n",
    "PATH = \"data/torch_models/state_dict_model.pt\"\n",
    "\n",
    "# Save\n",
    "torch.save(net.state_dict(), PATH)\n",
    "\n",
    "# Load\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fe6555cf-fd78-43d1-be76-133c52548960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007364153861999512\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "input_tensor = torch.Tensor(np.tile([0.0, 0.0, 0.0, 0.0, 0.0, 0.0], (1000, 1))) #.to(dev)\n",
    "s_t = time()\n",
    "for i in range(100):\n",
    "    model(input_tensor)\n",
    "e_t = (time() - s_t) / 100\n",
    "print(e_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fdfab0a3-41c7-454e-ba4a-9ffadde2ea9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc_in): Linear(in_features=6, out_features=100, bias=True)\n",
       "  (fc_hidden1): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (fc_hidden2): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (fc_hidden3): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (fc_out): Linear(in_features=100, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Specify a path\n",
    "PATH = \"data/torch_models/entire_model.pt\"\n",
    "\n",
    "# Save\n",
    "torch.save(net, PATH)\n",
    "\n",
    "# Load\n",
    "model = torch.load(PATH)\n",
    "model.to(dev)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60a29232-a851-49d8-b13e-a35d53553e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 6)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile([0.0, 0.0, 0.0, 0.0, 0.0, 0.0], (10, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "db7f6d81-c661-4674-807b-c59faeb971d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the relevant classes\n",
    "import numpy as np\n",
    "import uuid\n",
    "import os\n",
    "import pandas as pd\n",
    "import psutil\n",
    "import pickle\n",
    "#import kde_info\n",
    "#from lanfactory.config import \n",
    "#import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "#from tensorflow.keras.models import load_model\n",
    "#from tensorflow.python.client import device_lib\n",
    "\n",
    "import warnings\n",
    "from lanfactory.utils import try_gen_folder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, \n",
    "                file_IDs, \n",
    "                batch_size = 32,\n",
    "                label_prelog_cutoff_low = 1e-7,\n",
    "                label_prelog_cutoff_high = None\n",
    "                ):\n",
    "\n",
    "        # Initialization\n",
    "        self.batch_size = batch_size\n",
    "        self.file_IDs = file_IDs\n",
    "        self.indexes = np.arange(len(self.file_IDs))\n",
    "        self.label_prelog_cutoff_low = label_prelog_cutoff_low\n",
    "        self.label_prelog_cutoff_high = label_prelog_cutoff_high\n",
    "        self.tmp_data = None\n",
    "\n",
    "        # get metadata from loading a test file\n",
    "\n",
    "        self.__init_file_shape()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor((len(self.file_IDs) * self.file_shape_dict['inputs'][0]) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "\n",
    "        # Find list of IDs\n",
    "        if index % self.batches_per_file == 0 or self.tmp_data == None:\n",
    "            self.__load_file(file_index = self.indexes[index // self.batches_per_file])\n",
    "\n",
    "        # Generate data\n",
    "        batch_ids = np.arange(((index % self.batches_per_file) * self.batch_size), ((index % self.batches_per_file) + 1) * self.batch_size, 1)\n",
    "        X, y = self.__data_generation(batch_ids)\n",
    "        return X, y\n",
    "\n",
    "    def __load_file(self, file_index):\n",
    "        self.tmp_data = pickle.load(open(self.file_IDs[file_index], 'rb'))\n",
    "        shuffle_idx = np.random.choice(self.tmp_data['data'].shape[0], size = self.tmp_data['data'].shape[0], replace = True)\n",
    "        self.tmp_data['data'] = self.tmp_data['data'][shuffle_idx, :]\n",
    "        self.tmp_data['labels'] = self.tmp_data['labels'][shuffle_idx]\n",
    "        return\n",
    "        #return np.random.shuffle(np.load(self.training_data_folder + '/' + self.file_IDs[file_index]))\n",
    "\n",
    "    def __init_file_shape(self):\n",
    "        init_file = pickle.load(open(self.file_IDs[0], 'rb'))\n",
    "        #print('Init file shape: ', init_file['data'].shape, init_file['labels'].shape)\n",
    "        \n",
    "        self.file_shape_dict = {'inputs': init_file['data'].shape, 'labels': init_file['labels'].shape}\n",
    "        self.batches_per_file = int(self.file_shape_dict['inputs'][0] / self.batch_size)\n",
    "        self.input_dim = self.file_shape_dict['inputs'][1]\n",
    "        \n",
    "        if len(self.file_shape_dict['labels']) > 1:\n",
    "            self.label_dim = self.file_shape_dict['labels'][1]\n",
    "        else:\n",
    "            self.label_dim = 1\n",
    "        return\n",
    "\n",
    "    def __data_generation(self, batch_ids = None):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        X = torch.tensor(self.tmp_data['data'][batch_ids, :]) #tmp_file[batch_ids, :-1]\n",
    "        y = torch.unsqueeze(torch.tensor(self.tmp_data['labels'][batch_ids]),1) #tmp_file[batch_ids, -1]\n",
    "        \n",
    "        if self.label_prelog_cutoff_low is not None:\n",
    "            y[y < np.log(self.label_prelog_cutoff_low)] = np.log(self.label_prelog_cutoff_low)\n",
    "        \n",
    "        if self.label_prelog_cutoff_high is not None:\n",
    "            y[y > np.log(self.label_prelog_cutoff_high)] = np.log(self.label_prelog_cutoff_high)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "ef7b6ea5-4b39-43c1-93e0-d915a3966643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import uuid\n",
    "class TorchMLP(nn.Module):\n",
    "    def __init__(self, network_config = None, input_shape = 10, save_folder = None, generative_model_id = 'ddm'):\n",
    "        super(TorchMLP, self).__init__()\n",
    "        if generative_model_id is not None:\n",
    "            self.model_id = uuid.uuid1().hex + '_' + generative_model_id\n",
    "        else:\n",
    "            self.model_id = None\n",
    "            \n",
    "        self.save_folder = save_folder\n",
    "        self.input_shape = input_shape\n",
    "        self.network_config = network_config\n",
    "        self.activations = {'relu': torch.nn.ReLU(), 'tanh': torch.nn.Tanh()}\n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        self.layers.append(nn.Linear(input_shape, self.network_config['layer_sizes'][0]))\n",
    "        self.layers.append(self.activations[self.network_config['activations'][0]])\n",
    "        for i in range(len(self.network_config['layer_sizes']) - 1):\n",
    "            self.layers.append(nn.Linear(self.network_config['layer_sizes'][i], self.network_config['layer_sizes'][i + 1]))\n",
    "            print(self.network_config['activations'][i + 1])\n",
    "            if i < (len(self.network_config['layer_sizes']) - 2):\n",
    "                self.layers.append(self.activations[self.network_config['activations'][i + 1]])\n",
    "            else:\n",
    "                # skip last activation since\n",
    "                pass\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.layers) - 1):\n",
    "            x = self.layers[i](x)\n",
    "        return self.layers[i + 1](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f04b2bdc-1304-49e4-8bad-fc817f3a5219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'278ed526002e11ecb46da0423f3e9b42_ddm'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e080f5ba-0c7d-4127-b5fd-5aafaaaec99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReLU()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e7814cb7-019c-4513-976b-4765d1083a1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'momentum'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-386ef3b6f726>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'momentum'"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "13dedfb4-cebe-429f-98bc-97cbec562985",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainerTorchMLP:\n",
    "    def __init__(self, \n",
    "                 train_config = None,\n",
    "                 data_loader_train = None,\n",
    "                 data_loader_valid = None,\n",
    "                 torch_model = None,\n",
    "                 output_folder = None,\n",
    "                 warm_start = False,\n",
    "                 allow_abs_folder_generation = False,\n",
    "                 pin_memory = True):\n",
    "        \n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        self.dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        self.train_config = train_config\n",
    "        self.model = torch_model.to(self.dev)\n",
    "        self.output_folder = output_folder\n",
    "        self.allow_abs_folder_generation = allow_abs_folder_generation\n",
    "        self.data_loader_train = data_loader_train\n",
    "        self.data_loader_valid = data_loader_valid\n",
    "        self.warm_start = warm_start\n",
    "        self.pin_memory = pin_memory\n",
    "        \n",
    "        self.__get_loss()\n",
    "        self.__get_optimizer()\n",
    "        self.__load_weights()\n",
    "        \n",
    "    def __get_loss(self):\n",
    "        if self.train_config['loss'] == 'huber':\n",
    "            self.loss_fun = F.huber_loss\n",
    "        elif self.train_config['mse'] == 'mse':\n",
    "            self.loss_fun = F.mse_loss\n",
    "            \n",
    "    def __get_optimizer(self):\n",
    "        if self.train_config['optimizer'] == 'adam':\n",
    "            self.optimizer = optim.Adam(self.model.parameters())        \n",
    "        elif self.train_config['optimizer'] == 'sgd':\n",
    "            self.optimizer = optim.SGD(self.model.parameters())\n",
    "            \n",
    "    def __load_weights(self):\n",
    "        # for warmstart, not implemented at the moment\n",
    "        return\n",
    "    \n",
    "    def train_model(self, save_history = True, save_model = True, verbose = 1):\n",
    "        self.training_history = pd.DataFrame(np.zeros((self.train_config['n_epochs'], 2)), columns = ['epoch', 'val_loss'])\n",
    "        \n",
    "        for epoch in range(self.train_config['n_epochs']):\n",
    "            self.model.train()\n",
    "            cnt = 0\n",
    "            epoch_s_t = time()\n",
    "            #with tqdm.tqdm(self.data_loader_train , unit = 'batch') as tepoch:\n",
    "            for xb, yb in self.data_loader_train:\n",
    "                #tepoch.set_description('Epoch {}'.format(epoch))\n",
    "                if self.pin_memory and self.dev.__str__() == 'cuda':\n",
    "                    xb, yb = xb.cuda(non_blocking = True), yb.cuda(non_blocking = True)\n",
    "                else:\n",
    "                    xb, yb = xb.to(self.dev), yb.to(self.dev)\n",
    "\n",
    "                pred = self.model(xb)\n",
    "                loss = self.loss_fun(pred, yb)\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                if (cnt % 100) == 0 and verbose == 1:\n",
    "                    print('epoch: {}, batch: {} of {}, batch_loss: {}'.format(epoch, cnt, self.data_loader_train.__len__(), loss))\n",
    "                elif (cnt % 1000) == 0 and verbose == 2:\n",
    "                    print('epoch: {}, batch: {} of {}, batch_loss: {}'.format(epoch, cnt, self.data_loader_train.__len__(), loss))\n",
    "                cnt += 1\n",
    "\n",
    "            print('Epoch took {} seconds'.format(time() - epoch_s_t))\n",
    "            print('STARTING VALIDATION:')\n",
    "            self.model.eval()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                valid_loss = sum(self.loss_fun(self.model(xb.to(self.dev)), yb.to(self.dev)) for xb, yb in self.data_loader_valid) / self.data_loader_valid.__len__()\n",
    "            print('epoch {} / {}, validation_loss: {:2.4}'.format(epoch, self.train_config['n_epochs'], valid_loss))\n",
    "            \n",
    "            self.training_history.values[epoch, :] = [epoch, valid_loss]\n",
    "            \n",
    "        if save_model == True:\n",
    "            print('Saving model and training history')\n",
    "            pd.DataFrame(self.training_history).to_csv(self.output_folder + \"/\" + self.model.model_id + \"_torch_training_history.csv\")\n",
    "            torch.save(self.model.state_dict(), self.output_folder + \"/\" + self.model.model_id + \"_torch_state_dict.pt\")\n",
    "            \n",
    "class LoadTorchMLPInfer:\n",
    "    def __init__(file_path = None,\n",
    "                 network_config = None,\n",
    "                 input_dim = None):\n",
    "        \n",
    "        \n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        self.dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        self.model_file_path = file_path\n",
    "        self.network_config = network_config\n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        self.net = TorchMLP(network_config = self.network_config,\n",
    "                            input_dim = self.input_dim,\n",
    "                            generative_model_id = None)\n",
    "        self.net.load_state_dict(torch.load(self.model_file_path))\n",
    "        self.net.to(dev)\n",
    "        self.net.eval()\n",
    "        \n",
    "    def predict_on_batch(x = None):\n",
    "        return self.net(torch.from_numpy(x).to(dev))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7cb9e958-d96b-4aaa-b088-f5e9729bdcbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh\n",
      "tanh\n",
      "linear\n",
      "TorchMLP(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=6, out_features=100, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (5): Tanh()\n",
      "    (6): Linear(in_features=100, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Specify a path\n",
    "PATH = \"data/torch_models/state_dict_model.pt\"\n",
    "\n",
    "# Save\n",
    "torch.save(net.state_dict(), PATH)\n",
    "\n",
    "# Load\n",
    "model = TorchMLP(network_config = {'layer_types': ['dense', 'dense', 'dense'],\n",
    "                                  'layer_sizes': [100, 100, 100, 1],\n",
    "                                  'activations': ['tanh', 'tanh', 'tanh', 'linear'],\n",
    "                                  'loss': ['huber'],\n",
    "                                  'callbacks': ['checkpoint', 'earlystopping', 'reducelr']}, input_shape = 6)\n",
    "#model.load_state_dict(torch.load(PATH))\n",
    "#model.eval()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e25e297-291b-47a5-bec1-0c8523342c84",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-87f2ec5363b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ms_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0me_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ms_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/software/miniconda3/envs/lanfactory/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-c262047ed82d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'activations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "input_tensor = torch.Tensor(np.tile([0.0, 0.0, 0.0, 0.0, 0.0, 0.0], (1000, 1))) # .to(dev)\n",
    "s_t = time()\n",
    "for i in range(100):\n",
    "    model(input_tensor)\n",
    "e_t = (time() - s_t) / 100\n",
    "print(e_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "1d03688b-d325-40f8-8cc4-1819f4ab421c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide a unique identifier for the particular files you need from the training_data_folder\n",
    "training_file_identifier = 'ddm'\n",
    "train_file_excluder = ['par2', 'seq2']\n",
    "\n",
    "# Specify training data folder:\n",
    "training_data_folder = '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000'\n",
    "\n",
    "# Where do you want to save config files?\n",
    "network_train_config_save_folder = '/users/afengler/data/proj_lan_pipeline/LAN_scripts/config_files/'\n",
    "\n",
    "# Name of the config file\n",
    "network_train_config_save_name = 'network_train_config_ddm_nsim_200000_dt_0005_nps_500_npts_2000.pickle'\n",
    "\n",
    "# Get list of training files\n",
    "train_val_split = 0.9\n",
    "file_list = os.listdir(training_data_folder)\n",
    "valid_file_list = np.array([training_data_folder + '/' + \\\n",
    "                       file_ for file_ in file_list if (training_file_identifier in file_ and train_file_excluder[0] not in file_ and train_file_excluder[1] not in file_ )])\n",
    "val_idx_cutoff = int(0.9 * len(valid_file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47abcab9-ab58-4103-acfb-8016dd59e882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "bfed8777-58fc-478d-9b0a-1d567a724c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh\n",
      "tanh\n",
      "linear\n",
      "TorchMLP(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=6, out_features=100, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (5): Tanh()\n",
      "    (6): Linear(in_features=100, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'fadedeb8007811ecb46da0423f3e9b42_ddm'"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_network_config = {'layer_types': ['dense', 'dense', 'dense'],\n",
    "                                 'layer_sizes': [100, 100, 100, 1],\n",
    "                                 'activations': ['tanh', 'tanh', 'tanh', 'linear'],\n",
    "                                 'loss': ['huber'],\n",
    "                                 'callbacks': ['checkpoint', 'earlystopping', 'reducelr']}\n",
    "\n",
    "my_train_config = {'batch_size': 100000,\n",
    "                   'n_epochs': 5,\n",
    "                   'optimizer': 'adam',\n",
    "                   'learning_rate': 0.002,\n",
    "                   'loss': 'huber',\n",
    "                    'metrics': None,\n",
    "                    'callbacks': None}\n",
    "\n",
    "my_train_data = Dataset(file_IDs = valid_file_list[:val_idx_cutoff],\n",
    "                        batch_size = my_train_config['batch_size'],)\n",
    "my_valid_data = Dataset(file_IDs = valid_file_list[val_idx_cutoff:],\n",
    "                        batch_size = my_train_config['batch_size'])\n",
    "\n",
    "my_train_loader = torch.utils.data.DataLoader(my_train_data, batch_size = None, shuffle = True, num_workers = 10, pin_memory = True)\n",
    "my_valid_loader = torch.utils.data.DataLoader(my_train_data, batch_size = None, shuffle = True, num_workers = 10, pin_memory = True)\n",
    "\n",
    "\n",
    "net = TorchMLP(network_config = my_network_config, input_shape = 6)\n",
    "print(net)\n",
    "\n",
    "trainer = ModelTrainerTorchMLP(train_config = my_train_config,\n",
    "                               data_loader_train = my_train_loader,\n",
    "                               data_loader_valid = my_valid_loader,\n",
    "                               torch_model = net,\n",
    "                               output_folder = '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/torch_models/',\n",
    "                               warm_start = False,\n",
    "                               allow_abs_folder_generation = False)  \n",
    "\n",
    "trainer.model.model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "e2f76ff8-dd44-4c70-b975-4634f2fbd3cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute 'input_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-211-ed7d389f692b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_train_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'input_dim'"
     ]
    }
   ],
   "source": [
    "my_train_loader.input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7bcab805-e2f8-440c-ad59-720cf73c1996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7cdd1f34003211ecb46da0423f3e9b42_ddm'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5f8551-2e90-44c8-a138-455e5331ed01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch: 0 of 3510, batch_loss: 3.4872536659240723\n",
      "epoch: 0, batch: 100 of 3510, batch_loss: 1.926230549812317\n",
      "epoch: 0, batch: 200 of 3510, batch_loss: 0.6017950177192688\n",
      "epoch: 0, batch: 300 of 3510, batch_loss: 0.464552640914917\n",
      "epoch: 0, batch: 400 of 3510, batch_loss: 0.34960973262786865\n",
      "epoch: 0, batch: 500 of 3510, batch_loss: 0.28977394104003906\n",
      "epoch: 0, batch: 600 of 3510, batch_loss: 0.23863887786865234\n",
      "epoch: 0, batch: 700 of 3510, batch_loss: 0.21052594482898712\n",
      "epoch: 0, batch: 800 of 3510, batch_loss: 0.18897585570812225\n",
      "epoch: 0, batch: 900 of 3510, batch_loss: 0.18021658062934875\n",
      "epoch: 0, batch: 1000 of 3510, batch_loss: 0.17104624211788177\n",
      "epoch: 0, batch: 1100 of 3510, batch_loss: 0.15574601292610168\n",
      "epoch: 0, batch: 1200 of 3510, batch_loss: 0.15176177024841309\n",
      "epoch: 0, batch: 1300 of 3510, batch_loss: 0.14404910802841187\n",
      "epoch: 0, batch: 1400 of 3510, batch_loss: 0.13654905557632446\n",
      "epoch: 0, batch: 1500 of 3510, batch_loss: 0.13527114689350128\n",
      "epoch: 0, batch: 1600 of 3510, batch_loss: 0.12878043949604034\n"
     ]
    }
   ],
   "source": [
    "trainer.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c4fccd1d-8ae4-44c9-a996-e2c1ec582106",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got multiple values for argument 'file_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-30bfe566ea87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m inference_model = LoadTorchMLPInfer(file_path = '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/torch_models/' + trainer.model.model_id + '_torch_state_dict.pt', \n\u001b[1;32m      2\u001b[0m                                     \u001b[0mnetwork_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_network_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                                     input_dim = 6)\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got multiple values for argument 'file_path'"
     ]
    }
   ],
   "source": [
    "inference_model = LoadTorchMLPInfer(file_path = '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/torch_models/' + trainer.model.model_id + '_torch_state_dict.pt', \n",
    "                                    network_config = my_network_config,\n",
    "                                    input_dim = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7e04e27f-c58b-4af3-9113-688edab7e78b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict_on_batch() takes from 0 to 1 positional arguments but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-82b0fe3af1cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minference_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: predict_on_batch() takes from 0 to 1 positional arguments but 2 were given"
     ]
    }
   ],
   "source": [
    "inference_model.predict_on_batch(np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0], dtype = np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "0896a77b-ab63-42f1-991c-61d665bf1b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadTorchMLPInfer:\n",
    "    def __init__(self, \n",
    "                 model_file_path = None,\n",
    "                 network_config = None,\n",
    "                 input_dim = None):\n",
    "        \n",
    "        \n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        self.dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        self.model_file_path = model_file_path\n",
    "        self.network_config = network_config\n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        self.net = TorchMLP(network_config = self.network_config,\n",
    "                            input_shape = self.input_dim,\n",
    "                            generative_model_id = None)\n",
    "        self.net.load_state_dict(torch.load(self.model_file_path))\n",
    "        #self.net.half()\n",
    "        self.net.to(self.dev)\n",
    "        self.net.eval()\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def predict_on_batch(self, x = None):\n",
    "        return self.net(torch.from_numpy(x).to(self.dev)).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "37b55b22-8697-4a2e-963f-c12cf08a0982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh\n",
      "tanh\n",
      "linear\n"
     ]
    }
   ],
   "source": [
    "inference_model = LoadTorchMLPInfer(model_file_path = '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/torch_models/' + trainer.model.model_id + '_torch_state_dict.pt', \n",
    "                                    network_config = my_network_config,\n",
    "                                    input_dim = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "0a4529ee-debb-42e7-87cb-ac83d5dd8959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/torch_models/48dbe2ea004d11ecb46da0423f3e9b42_ddm_torch_state_dict.pt'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/torch_models/' + trainer.model.model_id + '_torch_state_dict.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "48878ba0-134d-4878-ac63-ad48dbc15eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00020326852798461915\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros((100, 6), dtype = np.float32) # , np.zeros((1000, 6), dtype = np.float), np.zeros((2000, 6), dtype = np.float32)]\n",
    "#x_tensor = torch.tensor(x).to(inference_model.dev)\n",
    "s_t = time()\n",
    "for i in range(100):\n",
    "    inference_model.predict_on_batch(x = x) # PYTORCH \n",
    "    #inference_model.net(x = x_tensor)\n",
    "print((time() - s_t) / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "18eedbf5-f834-4b44-ac27-27ddd740912e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "f26a2c7b-7708-497e-9638-d55ae5c9c652",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_keras_model = keras.models.load_model('/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/models/02938a2cf72911eb9d58a0423f3e9be0_ddm_ckpt.h5', compile = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "36dd1b62-deb1-49da-a905-2e88561ff5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002927823066711426\n"
     ]
    }
   ],
   "source": [
    "s_t = time()\n",
    "for i in range(100):\n",
    "    my_keras_model.predict_on_batch(x)\n",
    "    #inference_model.net(x = x_tensor)\n",
    "print((time() - s_t) / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dc0a5c-d44a-4b8c-a808-affd82c28a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               700       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 21,001\n",
      "Trainable params: 21,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfd508c-9aab-439e-be56-5c02e9b852b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lan_pipeline",
   "language": "python",
   "name": "lan_pipeline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
