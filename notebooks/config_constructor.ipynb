{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be7b9564-be61-46d4-9e86-8cc013f99654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append system path to include the config scripts\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "from copy import deepcopy\n",
    "\n",
    "from config import *\n",
    "import lanfactory\n",
    "import ssms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa9cfcf-8457-457b-8d83-4cd25f857bcc",
   "metadata": {},
   "source": [
    "# DATA GENERATOR CONFIGS\n",
    "#### Note: Look into the ssms package documentation to get a better idea about the kinds of configs that you need for different kinds of training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "211e022b-28b8-4ad2-8f50-3d3dc28f364b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_folder': 'data/lan_mlp/',\n",
       " 'dgp_list': 'ddm',\n",
       " 'nbins': 0,\n",
       " 'n_samples': 100000,\n",
       " 'n_parameter_sets': 10000,\n",
       " 'n_parameter_sets_rejected': 100,\n",
       " 'n_training_samples_by_parameter_set': 1000,\n",
       " 'max_t': 20.0,\n",
       " 'delta_t': 0.001,\n",
       " 'pickleprotocol': 4,\n",
       " 'n_cpus': 'all',\n",
       " 'kde_data_mixture_probabilities': [0.8, 0.1, 0.1],\n",
       " 'simulation_filters': {'mode': 20,\n",
       "  'choice_cnt': 10,\n",
       "  'mean_rt': 15,\n",
       "  'std': 0,\n",
       "  'mode_cnt_rel': 0.5},\n",
       " 'negative_rt_cutoff': -66.77497,\n",
       " 'n_subruns': 10,\n",
       " 'bin_pointwise': False,\n",
       " 'separate_response_channels': False}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssms.config.data_generator_config['lan']['mlp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3e843d7-5682-402e-b393-d7ae9fbe09a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found folder:  /users\n",
      "Moving on...\n",
      "Found folder:  /users/afengler\n",
      "Moving on...\n",
      "Found folder:  /users/afengler/data\n",
      "Moving on...\n",
      "Found folder:  /users/afengler/data/proj_lan_pipeline\n",
      "Moving on...\n",
      "Found folder:  /users/afengler/data/proj_lan_pipeline/LAN_scripts\n",
      "Moving on...\n",
      "Found folder:  /users/afengler/data/proj_lan_pipeline/LAN_scripts/config_files\n",
      "Moving on...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_config': {'name': 'race_no_bias_4',\n",
       "  'params': ['v0', 'v1', 'v2', 'v3', 'a', 'z', 'ndt'],\n",
       "  'param_bounds': [[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       "   [2.5, 2.5, 2.5, 2.5, 3.0, 0.9, 2.0]],\n",
       "  'boundary': <function ssms.basic_simulators.boundary_functions.constant(t=0)>,\n",
       "  'n_params': 7,\n",
       "  'default_params': [0.0, 0.0, 0.0, 0.0, 2.0, 0.5, 0.001],\n",
       "  'hddm_include': ['v0', 'v1', 'v2', 'a', 'z', 'ndt'],\n",
       "  'nchoices': 4},\n",
       " 'data_config': {'output_folder': 'data/lan_mlp/',\n",
       "  'dgp_list': 'race_no_bias_4',\n",
       "  'nbins': 0,\n",
       "  'n_samples': 200000,\n",
       "  'n_parameter_sets': 1000,\n",
       "  'n_parameter_sets_rejected': 100,\n",
       "  'n_training_samples_by_parameter_set': 2000,\n",
       "  'max_t': 20.0,\n",
       "  'delta_t': 0.001,\n",
       "  'pickleprotocol': 4,\n",
       "  'n_cpus': 'all',\n",
       "  'kde_data_mixture_probabilities': [0.8, 0.1, 0.1],\n",
       "  'simulation_filters': {'mode': 20,\n",
       "   'choice_cnt': 5,\n",
       "   'mean_rt': 15,\n",
       "   'std': 0,\n",
       "   'mode_cnt_rel': 0.6},\n",
       "  'negative_rt_cutoff': -66.77497,\n",
       "  'n_subruns': 5,\n",
       "  'bin_pointwise': False,\n",
       "  'separate_response_channels': False}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify model\n",
    "model = 'race_no_bias_4'\n",
    "\n",
    "# Where do you want to save the config file?\n",
    "config_save_folder = '/users/afengler/data/proj_lan_pipeline/LAN_scripts/config_files/'\n",
    "\n",
    "# Name of the config file\n",
    "data_config_save_name = 'race_no_bias_4_nsim_200000_dt_001_nps_1000_npts_2000.pickle'\n",
    "\n",
    "# What kind of likelihood approximator are we generating training data for?\n",
    "generator_approach = 'lan'\n",
    "\n",
    "# Specific network type we train? (Might affect training data representation needed)\n",
    "generator_network_type = 'mlp'\n",
    "\n",
    "# Specify arguments which you want to adjust in the data generator\n",
    "data_generator_arg_dict = {'dgp_list': model,\n",
    "                           'n_samples': 200000,\n",
    "                           'n_parameter_sets': 1000,\n",
    "                           'delta_t': 0.001,\n",
    "                           'n_training_samples_by_parameter_set': 2000,\n",
    "                           'n_subruns': 5}\n",
    "\n",
    "# model_config_arg_dict = {'param_bounds': [[-2.5, 0.2, 0.1, 0.0],\n",
    "#                                           [2.5, 2.2, 0.9, 2.0]]}\n",
    "model_config_arg_dict = {}\n",
    "\n",
    "make_data_generator_configs(model = model,\n",
    "                            generator_approach = 'lan',\n",
    "                            generator_network_type = 'mlp',\n",
    "                            data_generator_arg_dict = data_generator_arg_dict,\n",
    "                            model_config_arg_dict = model_config_arg_dict,\n",
    "                            save_name = data_config_save_name,\n",
    "                            save_folder = config_save_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3e579d-1f16-4abb-81fa-9d4252d8ec69",
   "metadata": {},
   "source": [
    "# NETWORK AND TRAIN CONFIGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d36d7100-1257-47bb-9565-cfd83e3d6c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found folder:  /users\n",
      "Moving on...\n",
      "Found folder:  /users/afengler\n",
      "Moving on...\n",
      "Found folder:  /users/afengler/data\n",
      "Moving on...\n",
      "Found folder:  /users/afengler/data/proj_lan_pipeline\n",
      "Moving on...\n",
      "Found folder:  /users/afengler/data/proj_lan_pipeline/LAN_scripts\n",
      "Moving on...\n",
      "Found folder:  /users/afengler/data/proj_lan_pipeline/LAN_scripts/config_files\n",
      "Moving on...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'network_config': {'layer_types': ['dense', 'dense', 'dense'],\n",
       "  'layer_sizes': [100, 100, 1],\n",
       "  'activations': ['tanh', 'tanh', 'linear'],\n",
       "  'loss': ['huber'],\n",
       "  'callbacks': ['checkpoint', 'earlystopping', 'reducelr']},\n",
       " 'train_config': {'batch_size': 50000,\n",
       "  'n_epochs': 200,\n",
       "  'optimizer': 'adam',\n",
       "  'learning_rate': 0.002,\n",
       "  'loss': 'huber',\n",
       "  'metrics': [<tensorflow.python.keras.losses.MeanSquaredError at 0x7f9db2b8f450>,\n",
       "   <tensorflow.python.keras.losses.Huber at 0x7fa06a9a5490>],\n",
       "  'callbacks': ['checkpoint', 'earlystopping', 'reducelr'],\n",
       "  'training_files': array(['/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_ddm_75daaf9ef64b11ebb86cac1f6b627e10.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_ddm_36d0d238f64b11eb83ba0cc47afe4c38.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_ddm_1590f160f64c11eb87b8ac1f6bb2f5ac.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_ddm_a4e51a4af64b11ebb61bac1f6b1b78a6.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_ddm_53e135b6f64b11eb9a87ac1f6b1b78b6.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_ddm_4eb7adb2f64c11eb9fa0ac1f6bb04754.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_ddm_dadc2314f64b11eb9769ac1f6bb05b50.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_ddm_e0df2202f64b11ebb62fac1f6bb2f590.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_ddm_7dd35b74f64b11eb98e1ac1f6b63e9de.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_ddm_0cec8d1cf64c11eba3670cc47afe4c52.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_ddm_c9b42bf4f64b11eb90b9ac1f6b627e32.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_ddm_77b931b4f64b11eb9b07ac1f6b627e8e.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_ddm_4caad4a0f64b11eba968ac1f6b1b78fa.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_ddm_23fc5028f64c11ebba170cc47afe4c43.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_ddm_802fe18af64b11eb8d9cac1f6b63e9f4.pickle'],\n",
       "        dtype='<U154'),\n",
       "  'validation_files': array(['/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_ddm_1b0f0e6af64c11ebad22ac1f6bb04984.pickle',\n",
       "         '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000/training_data_ddm_26a5a244f64b11ebbc9bac1f6b1b7bac.pickle'],\n",
       "        dtype='<U154'),\n",
       "  'shuffle_files': True,\n",
       "  'label_prelog_cutoff_low': 1e-07,\n",
       "  'label_prelog_cutoff_high': None,\n",
       "  'save_history': True}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Provide a unique identifier for the particular files you need from the training_data_folder\n",
    "training_file_identifier = 'ddm'\n",
    "\n",
    "# Specify training data folder:\n",
    "training_data_folder = '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000'\n",
    "\n",
    "# Where do you want to save config files?\n",
    "network_train_config_save_folder = '/users/afengler/data/proj_lan_pipeline/LAN_scripts/config_files/'\n",
    "\n",
    "# Name of the config file\n",
    "network_train_config_save_name = 'network_train_config_ddm_nsim_200000_dt_0005_nps_500_npts_2000.pickle'\n",
    "\n",
    "# Get list of training files\n",
    "train_val_split = 0.9\n",
    "file_list = os.listdir(training_data_folder)\n",
    "valid_file_list = np.array([training_data_folder + '/' + \\\n",
    "                       file_ for file_ in file_list if training_file_identifier in file_])\n",
    "val_idx_cutoff = int(0.9 * len(valid_file_list))\n",
    "\n",
    "# Specify the arguments which you want to adjust in the network and train configs\n",
    "# Check lanfactory.config.network_config_mlp\n",
    "#.      lanfactor.config.train_config_mlp for details\n",
    "\n",
    "network_arg_dict = {'layer_types': ['dense' for i in range(4)],\n",
    "                    'layer_sizes': [100, 100, 100, 1],\n",
    "                    'activations': ['tanh', 'tanh', 'tanh', 'linear'],\n",
    "                    'loss': ['huber'],\n",
    "                    'model_id': training_file_identifier\n",
    "                   }\n",
    "                    \n",
    "train_arg_dict = {'batch_size': 50000,\n",
    "                  'n_epochs': 200,\n",
    "                  'training_files': valid_file_list[:val_idx_cutoff],\n",
    "                  'validation_files': valid_file_list[val_idx_cutoff:],\n",
    "                  'shuffle_files': True,\n",
    "                  'label_prelog_cutoff_low': 1e-7,\n",
    "                  'label_prelog_cutoff_high': None,\n",
    "                  'save_history': True,\n",
    "                  'callbacks': ['checkpoint', 'earlystopping', 'reducelr']\n",
    "                 }\n",
    "\n",
    "make_train_network_configs(save_folder = network_train_config_save_folder,\n",
    "                           network_arg_dict = network_arg_dict,\n",
    "                           train_arg_dict = train_arg_dict,\n",
    "                           save_name = network_train_config_save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d1bd45b-1d18-4df8-8f59-bfc49ffebe43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PRINT\n",
      "0\n",
      "NEW PRINT\n",
      "1\n",
      "NEW PRINT\n",
      "2\n",
      "NEW PRINT\n",
      "3\n",
      "NEW PRINT\n",
      "4\n",
      "NEW PRINT\n",
      "5\n",
      "NEW PRINT\n",
      "6\n",
      "NEW PRINT\n",
      "7\n",
      "NEW PRINT\n",
      "8\n",
      "NEW PRINT\n",
      "9\n",
      "NEW PRINT\n",
      "10\n",
      "NEW PRINT\n",
      "11\n",
      "NEW PRINT\n",
      "12\n",
      "NEW PRINT\n",
      "13\n",
      "NEW PRINT\n",
      "14\n",
      "NEW PRINT\n",
      "15\n",
      "NEW PRINT\n",
      "16\n",
      "NEW PRINT\n",
      "17\n",
      "NEW PRINT\n",
      "18\n",
      "NEW PRINT\n",
      "19\n",
      "NEW PRINT\n",
      "20\n",
      "NEW PRINT\n",
      "21\n",
      "NEW PRINT\n",
      "22\n",
      "NEW PRINT\n",
      "23\n",
      "NEW PRINT\n",
      "24\n",
      "NEW PRINT\n",
      "25\n",
      "NEW PRINT\n",
      "26\n",
      "NEW PRINT\n",
      "27\n",
      "NEW PRINT\n",
      "28\n",
      "NEW PRINT\n",
      "29\n",
      "NEW PRINT\n",
      "30\n",
      "NEW PRINT\n",
      "31\n",
      "NEW PRINT\n",
      "32\n",
      "NEW PRINT\n",
      "33\n",
      "NEW PRINT\n",
      "34\n",
      "NEW PRINT\n",
      "35\n",
      "NEW PRINT\n",
      "36\n",
      "NEW PRINT\n",
      "37\n",
      "NEW PRINT\n",
      "38\n",
      "NEW PRINT\n",
      "39\n",
      "NEW PRINT\n",
      "40\n",
      "NEW PRINT\n",
      "41\n",
      "NEW PRINT\n",
      "42\n",
      "NEW PRINT\n",
      "43\n",
      "NEW PRINT\n",
      "44\n",
      "NEW PRINT\n",
      "45\n",
      "NEW PRINT\n",
      "46\n",
      "NEW PRINT\n",
      "47\n",
      "NEW PRINT\n",
      "48\n",
      "NEW PRINT\n",
      "49\n",
      "NEW PRINT\n",
      "50\n",
      "NEW PRINT\n",
      "51\n",
      "NEW PRINT\n",
      "52\n",
      "NEW PRINT\n",
      "53\n",
      "NEW PRINT\n",
      "54\n",
      "NEW PRINT\n",
      "55\n",
      "NEW PRINT\n",
      "56\n",
      "NEW PRINT\n",
      "57\n",
      "NEW PRINT\n",
      "58\n",
      "NEW PRINT\n",
      "59\n",
      "NEW PRINT\n",
      "60\n",
      "NEW PRINT\n",
      "61\n",
      "NEW PRINT\n",
      "62\n",
      "NEW PRINT\n",
      "63\n",
      "NEW PRINT\n",
      "64\n",
      "NEW PRINT\n",
      "65\n",
      "NEW PRINT\n",
      "66\n",
      "NEW PRINT\n",
      "67\n",
      "NEW PRINT\n",
      "68\n",
      "NEW PRINT\n",
      "69\n",
      "NEW PRINT\n",
      "70\n",
      "NEW PRINT\n",
      "71\n",
      "NEW PRINT\n",
      "72\n",
      "NEW PRINT\n",
      "73\n",
      "NEW PRINT\n",
      "74\n",
      "NEW PRINT\n",
      "75\n",
      "NEW PRINT\n",
      "76\n",
      "NEW PRINT\n",
      "77\n",
      "NEW PRINT\n",
      "78\n",
      "NEW PRINT\n",
      "79\n",
      "NEW PRINT\n",
      "80\n",
      "NEW PRINT\n",
      "81\n",
      "NEW PRINT\n",
      "82\n",
      "NEW PRINT\n",
      "83\n",
      "NEW PRINT\n",
      "84\n",
      "NEW PRINT\n",
      "85\n",
      "NEW PRINT\n",
      "86\n",
      "NEW PRINT\n",
      "87\n",
      "NEW PRINT\n",
      "88\n",
      "NEW PRINT\n",
      "89\n"
     ]
    }
   ],
   "source": [
    "# Name of the config file\n",
    "network_train_config_save_name = 'network_train_config_lca_no_bias_4_architecture_search_test.pickle'\n",
    "\n",
    "# Where do you want to save config files?\n",
    "network_train_config_save_folder = '/users/afengler/data/proj_lan_pipeline/LAN_scripts/config_files/'\n",
    "\n",
    "# Specify training data folder:\n",
    "training_data_folder = '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000'\n",
    "\n",
    "# Provide a unique identifier for the particular files you need from the training_data_folder\n",
    "training_file_identifier = 'lca_no_bias_4'\n",
    "\n",
    "# Get list of relevant training files\n",
    "train_val_split = 0.9\n",
    "file_list = os.listdir(training_data_folder)\n",
    "valid_file_list = np.array([training_data_folder + '/' + \\\n",
    "                     file_ for file_ in file_list if training_file_identifier in file_])\n",
    "val_idx_cutoff = int(0.9 * len(valid_file_list))\n",
    "\n",
    "# Training config hyperparameters\n",
    "layer_sizes = [[100, 100, 1], [100, 100, 100, 1], [100, 100, 100, 100, 1],\n",
    "               [100, 100, 1], [100, 100, 100, 1], [100, 100, 100, 100, 1],\n",
    "               [100, 100, 1], [100, 100, 100, 1], [100, 100, 100, 100, 1],\n",
    "               [200, 200, 1], [200, 200, 200, 1], [200, 200, 200, 200, 1],\n",
    "               [200, 200, 1], [200, 200, 200, 1], [200, 200, 200, 200, 1],\n",
    "               [200, 200, 1], [200, 200, 200, 1], [200, 200, 200, 200, 1]\n",
    "              ]\n",
    "layer_types = [['dense', 'dense', 'dense'], ['dense', 'dense', 'dense', 'dense'], ['dense', 'dense', 'dense', 'dense', 'dense'],\n",
    "               ['dense', 'dense', 'dense'], ['dense', 'dense', 'dense', 'dense'], ['dense', 'dense', 'dense', 'dense', 'dense'],\n",
    "               ['dense', 'dense', 'dense'], ['dense', 'dense', 'dense', 'dense'], ['dense', 'dense', 'dense', 'dense', 'dense'],\n",
    "               ['dense', 'dense', 'dense'], ['dense', 'dense', 'dense', 'dense'], ['dense', 'dense', 'dense', 'dense', 'dense'],\n",
    "               ['dense', 'dense', 'dense'], ['dense', 'dense', 'dense', 'dense'], ['dense', 'dense', 'dense', 'dense', 'dense'],\n",
    "               ['dense', 'dense', 'dense'], ['dense', 'dense', 'dense', 'dense'], ['dense', 'dense', 'dense', 'dense', 'dense'],\n",
    "              ]\n",
    "activations = [['tanh', 'tanh', 'linear'], ['tanh', 'tanh', 'tanh', 'linear'], ['tanh', 'tanh', 'tanh', 'tanh', 'linear'],\n",
    "               ['relu', 'tanh', 'linear'], ['relu', 'relu', 'tanh', 'linear'], ['relu', 'relu', 'relu', 'tanh', 'linear'],\n",
    "               ['relu', 'relu', 'linear'], ['relu', 'relu', 'relu', 'linear'], ['relu', 'relu', 'relu', 'relu', 'linear'],\n",
    "               ['tanh', 'tanh', 'linear'], ['tanh', 'tanh', 'tanh', 'linear'], ['tanh', 'tanh', 'tanh', 'tanh', 'linear'],\n",
    "               ['relu', 'tanh', 'linear'], ['relu', 'relu', 'tanh', 'linear'], ['relu', 'relu', 'relu', 'tanh', 'linear'],\n",
    "               ['relu', 'relu', 'linear'], ['relu', 'relu', 'relu', 'linear'], ['relu', 'relu', 'relu', 'relu', 'linear'],\n",
    "              ]\n",
    "\n",
    "batch_size = 50000\n",
    "n_epochs = 200\n",
    "n_training_files = [50, 100, 200, 300, val_idx_cutoff]\n",
    "\n",
    "# Loop objects\n",
    "config_dict = {}\n",
    "network_arg_dicts = {}\n",
    "train_arg_dicts = {}    \n",
    "cnt = 0\n",
    "\n",
    "for i in range(len(layer_sizes)):\n",
    "    for j in range(len(n_training_files)):\n",
    "        # Specify the arguments which you want to adjust in the network and train configs\n",
    "        # Check lanfactory.config.network_config_mlp\n",
    "        #.      lanfactor.config.train_config_mlp for details\n",
    "\n",
    "        network_arg_dict = {'layer_types': layer_types[i],\n",
    "                            'layer_sizes': layer_sizes[i],\n",
    "                            'activations': activations[i],\n",
    "                            'loss': ['huber'],\n",
    "                            'model_id': training_file_identifier\n",
    "                            }\n",
    "\n",
    "        train_arg_dict = {'batch_size': batch_size,\n",
    "                          'n_epochs': n_epochs,\n",
    "                          'training_files': valid_file_list[:n_training_files[j]],\n",
    "                          'validation_files': valid_file_list[val_idx_cutoff:],\n",
    "                          'shuffle_files': True,\n",
    "                          'label_prelog_cutoff_low': 1e-7,\n",
    "                          'label_prelog_cutoff_high': None,\n",
    "                          'save_history': True,\n",
    "                          'callbacks': ['checkpoint', 'earlystopping', 'reducelr']  # ['checkpoint', 'earlystopping', 'reducelr']\n",
    "                          }\n",
    "\n",
    "        config_dict[cnt] = make_train_network_configs(save_folder = network_train_config_save_folder,\n",
    "                                                      network_arg_dict = network_arg_dict,\n",
    "                                                      train_arg_dict = train_arg_dict,\n",
    "                                                      save_name = None)\n",
    "        print('NEW PRINT')\n",
    "        print(cnt)\n",
    "        #print(config_dict[0]['network_config'])\n",
    "        cnt += 1\n",
    "\n",
    "pickle.dump(config_dict, open(network_train_config_save_folder + network_train_config_save_name, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f7d1af0-a2fa-4da3-878e-35edb3a4f292",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pickle.load(open(network_train_config_save_folder + network_train_config_save_name, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8ab8435-3dd1-4b0f-9d83-8832add0d500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "100\n",
      "200\n",
      "300\n",
      "463\n",
      "50\n",
      "100\n",
      "200\n",
      "300\n",
      "463\n",
      "50\n",
      "100\n",
      "200\n",
      "300\n",
      "463\n",
      "50\n",
      "100\n",
      "200\n",
      "300\n",
      "463\n",
      "50\n",
      "100\n",
      "200\n",
      "300\n",
      "463\n",
      "50\n",
      "100\n",
      "200\n",
      "300\n",
      "463\n",
      "50\n",
      "100\n",
      "200\n",
      "300\n",
      "463\n",
      "50\n",
      "100\n",
      "200\n",
      "300\n",
      "463\n",
      "50\n",
      "100\n",
      "200\n",
      "300\n",
      "463\n",
      "50\n",
      "100\n",
      "200\n",
      "300\n",
      "463\n",
      "50\n",
      "100\n",
      "200\n",
      "300\n",
      "463\n",
      "50\n",
      "100\n",
      "200\n",
      "300\n",
      "463\n",
      "50\n",
      "100\n",
      "200\n",
      "300\n",
      "463\n",
      "50\n",
      "100\n",
      "200\n",
      "300\n",
      "463\n",
      "50\n",
      "100\n",
      "200\n",
      "300\n",
      "463\n",
      "50\n",
      "100\n",
      "200\n",
      "300\n",
      "463\n",
      "50\n",
      "100\n",
      "200\n",
      "300\n",
      "463\n",
      "50\n",
      "100\n",
      "200\n",
      "300\n",
      "463\n"
     ]
    }
   ],
   "source": [
    "for i in range(90):\n",
    "    print(x[i]['train_config']['training_files'].shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e09462-5720-4883-a7d9-9d064f76435c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lanfactory",
   "language": "python",
   "name": "lanfactory"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
