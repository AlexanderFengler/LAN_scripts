{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9b9d212-5fa7-4b88-b57d-ce2957e5a586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing lanfactory\n",
      "importing ssms\n",
      "importing hddm\n",
      "importing lanfactory\n",
      "importing ssms\n",
      "importing hddm\n"
     ]
    }
   ],
   "source": [
    "# Append system path to include the config scripts\n",
    "import sys\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "print('importing lanfactory')\n",
    "import lanfactory\n",
    "\n",
    "print('importing ssms')\n",
    "import ssms\n",
    "\n",
    "print('importing hddm')\n",
    "import hddm\n",
    "\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "from config import *\n",
    "import config\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from kabuki.analyze import gelman_rubin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fbd223-e2f5-4680-843a-1544e5c45127",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(lanfactory.trainers.torch_mlp.LoadTorchMLPInfer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71691fa-07ee-4a55-8d6e-fafabbe65404",
   "metadata": {},
   "outputs": [],
   "source": [
    "lanfactory.trainers.torch_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ffd4781-6663-4b9a-9d0c-f7954cc2daee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh\n",
      "tanh\n",
      "tanh\n",
      "tanh\n",
      "linear\n"
     ]
    }
   ],
   "source": [
    "network_config = pickle.load(open('data/torch_models/gamma_drift/7ad1d000ccb411ec8d600cc47afe4c34_gamma_drift_torch__network_config.pickle', 'rb'))\n",
    "network = lanfactory.trainers.torch_mlp.LoadTorchMLPInfer(model_file_path = 'data/torch_models/gamma_drift/7ad1d000ccb411ec8d600cc47afe4c34_gamma_drift_torch_state_dict.pt',\n",
    "                                                network_config = network_config,\n",
    "                                                input_dim = len(ssms.config.model_config['gamma_drift']['params']) + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62cd407f-4f23-4d86-a407-4ac2e7b181a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function tile in module numpy:\n",
      "\n",
      "tile(A, reps)\n",
      "    Construct an array by repeating A the number of times given by reps.\n",
      "    \n",
      "    If `reps` has length ``d``, the result will have dimension of\n",
      "    ``max(d, A.ndim)``.\n",
      "    \n",
      "    If ``A.ndim < d``, `A` is promoted to be d-dimensional by prepending new\n",
      "    axes. So a shape (3,) array is promoted to (1, 3) for 2-D replication,\n",
      "    or shape (1, 1, 3) for 3-D replication. If this is not the desired\n",
      "    behavior, promote `A` to d-dimensions manually before calling this\n",
      "    function.\n",
      "    \n",
      "    If ``A.ndim > d``, `reps` is promoted to `A`.ndim by pre-pending 1's to it.\n",
      "    Thus for an `A` of shape (2, 3, 4, 5), a `reps` of (2, 2) is treated as\n",
      "    (1, 1, 2, 2).\n",
      "    \n",
      "    Note : Although tile may be used for broadcasting, it is strongly\n",
      "    recommended to use numpy's broadcasting operations and functions.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    A : array_like\n",
      "        The input array.\n",
      "    reps : array_like\n",
      "        The number of repetitions of `A` along each axis.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    c : ndarray\n",
      "        The tiled output array.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    repeat : Repeat elements of an array.\n",
      "    broadcast_to : Broadcast an array to a new shape\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([0, 1, 2])\n",
      "    >>> np.tile(a, 2)\n",
      "    array([0, 1, 2, 0, 1, 2])\n",
      "    >>> np.tile(a, (2, 2))\n",
      "    array([[0, 1, 2, 0, 1, 2],\n",
      "           [0, 1, 2, 0, 1, 2]])\n",
      "    >>> np.tile(a, (2, 1, 2))\n",
      "    array([[[0, 1, 2, 0, 1, 2]],\n",
      "           [[0, 1, 2, 0, 1, 2]]])\n",
      "    \n",
      "    >>> b = np.array([[1, 2], [3, 4]])\n",
      "    >>> np.tile(b, 2)\n",
      "    array([[1, 2, 1, 2],\n",
      "           [3, 4, 3, 4]])\n",
      "    >>> np.tile(b, (2, 1))\n",
      "    array([[1, 2],\n",
      "           [3, 4],\n",
      "           [1, 2],\n",
      "           [3, 4]])\n",
      "    \n",
      "    >>> c = np.array([1,2,3,4])\n",
      "    >>> np.tile(c,(4,1))\n",
      "    array([[1, 2, 3, 4],\n",
      "           [1, 2, 3, 4],\n",
      "           [1, 2, 3, 4],\n",
      "           [1, 2, 3, 4]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.tile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e5f7bb85-7376-4428-ba0c-0a7359acbc25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f94090c2-117c-4270-9990-d2f2a0ebd549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "40f5edac-bfd8-4567-9119-93e13cb51a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rts[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df8d030c-9729-4043-94d3-dd3f1ad1a1c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params_tmp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-11b32ad4b27a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_tmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrts_tmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrts_tmp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mchoices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnet_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchoices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'params_tmp' is not defined"
     ]
    }
   ],
   "source": [
    "x = np.tile(np.array(params_tmp), reps = (2000, 1))\n",
    "rts = np.expand_dims(np.concatenate([rts_tmp[::-1], rts_tmp]), axis = 1)\n",
    "choices = np.expand_dims(np.concatenate( [np.repeat(-1, 1000), np.repeat(1, 1000)]), axis = 1)\n",
    "net_input = np.hstack([x, rts, choices]).astype(np.float32)                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "818851d8-77e4-48a3-8a41-fc222630ca90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2776508e-07],\n",
       "       [1.2798337e-07],\n",
       "       [1.2820448e-07],\n",
       "       ...,\n",
       "       [1.4578460e-07],\n",
       "       [1.4508848e-07],\n",
       "       [1.4440670e-07]], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(network.predict_on_batch(net_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49258d75-a1e8-4e04-8381-02fe39f939d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['v', 'a', 'z', 't', 'shape', 'scale', 'c']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssms.config.model_config['gamma_drift']['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfe600bf-c0b2-4d8c-b7ba-d7539f1ec537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 1.0, 0.5, 0.25, 5.0, 0.5, 1.0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssms.config.model_config['gamma_drift']['default_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cadafa7d-89e9-42c6-9bf3-930345e8fd6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7faa943c9c90>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "params_tmp = ssms.config.model_config['gamma_drift']['default_params']\n",
    "params_tmp[ssms.config.model_config['gamma_drift']['params'].index('c')] = -2\n",
    "params_tmp[ssms.config.model_config['gamma_drift']['params'].index('shape')] = 1.2\n",
    "#params_tmp[ssms.config.model_config['gamma_drift']['params'].index('shape')] = 1.2\n",
    "\n",
    "\n",
    "# Make network input\n",
    "x = np.tile(np.array(params_tmp), reps = (2000, 1))\n",
    "rts_tmp = np.linspace(0, 10, 1000)\n",
    "rts = np.expand_dims(np.concatenate([rts_tmp[::-1], rts_tmp]), axis = 1)\n",
    "choices = np.expand_dims(np.concatenate( [np.repeat(-1, 1000), np.repeat(1, 1000)]), axis = 1)\n",
    "net_input = np.hstack([x, rts, choices]).astype(np.float32)  \n",
    "\n",
    "\n",
    "sim_out = ssms.basic_simulators.simulator(params_tmp, model='gamma_drift', n_samples = 10000)\n",
    "plt.hist(sim_out['rts'] * sim_out['choices'], bins = 30, histtype = 'step', density = True)\n",
    "plt.plot(rts * choices, np.exp(network.predict_on_batch(net_input)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eae16a-c4ae-4682-868f-e8b4550c79ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "421288a6-a1ee-4d5f-8515-62844c2fe893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc_in): Linear(in_features=6, out_features=100, bias=True)\n",
       "  (fc_hidden1): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (fc_hidden2): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (fc_out): Linear(in_features=100, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify a path\n",
    "PATH = \"data/torch_models/state_dict_model.pt\"\n",
    "\n",
    "# Save\n",
    "torch.save(net.state_dict(), PATH)\n",
    "\n",
    "# Load\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fe6555cf-fd78-43d1-be76-133c52548960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007364153861999512\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "input_tensor = torch.Tensor(np.tile([0.0, 0.0, 0.0, 0.0, 0.0, 0.0], (1000, 1))) #.to(dev)\n",
    "s_t = time()\n",
    "for i in range(100):\n",
    "    model(input_tensor)\n",
    "e_t = (time() - s_t) / 100\n",
    "print(e_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fdfab0a3-41c7-454e-ba4a-9ffadde2ea9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc_in): Linear(in_features=6, out_features=100, bias=True)\n",
       "  (fc_hidden1): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (fc_hidden2): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (fc_hidden3): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (fc_out): Linear(in_features=100, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Specify a path\n",
    "PATH = \"data/torch_models/entire_model.pt\"\n",
    "\n",
    "# Save\n",
    "torch.save(net, PATH)\n",
    "\n",
    "# Load\n",
    "model = torch.load(PATH)\n",
    "model.to(dev)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60a29232-a851-49d8-b13e-a35d53553e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 6)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile([0.0, 0.0, 0.0, 0.0, 0.0, 0.0], (10, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "db7f6d81-c661-4674-807b-c59faeb971d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the relevant classes\n",
    "import numpy as np\n",
    "import uuid\n",
    "import os\n",
    "import pandas as pd\n",
    "import psutil\n",
    "import pickle\n",
    "#import kde_info\n",
    "#from lanfactory.config import \n",
    "#import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "#from tensorflow.keras.models import load_model\n",
    "#from tensorflow.python.client import device_lib\n",
    "\n",
    "import warnings\n",
    "from lanfactory.utils import try_gen_folder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, \n",
    "                file_IDs, \n",
    "                batch_size = 32,\n",
    "                label_prelog_cutoff_low = 1e-7,\n",
    "                label_prelog_cutoff_high = None\n",
    "                ):\n",
    "\n",
    "        # Initialization\n",
    "        self.batch_size = batch_size\n",
    "        self.file_IDs = file_IDs\n",
    "        self.indexes = np.arange(len(self.file_IDs))\n",
    "        self.label_prelog_cutoff_low = label_prelog_cutoff_low\n",
    "        self.label_prelog_cutoff_high = label_prelog_cutoff_high\n",
    "        self.tmp_data = None\n",
    "\n",
    "        # get metadata from loading a test file\n",
    "\n",
    "        self.__init_file_shape()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor((len(self.file_IDs) * self.file_shape_dict['inputs'][0]) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "\n",
    "        # Find list of IDs\n",
    "        if index % self.batches_per_file == 0 or self.tmp_data == None:\n",
    "            self.__load_file(file_index = self.indexes[index // self.batches_per_file])\n",
    "\n",
    "        # Generate data\n",
    "        batch_ids = np.arange(((index % self.batches_per_file) * self.batch_size), ((index % self.batches_per_file) + 1) * self.batch_size, 1)\n",
    "        X, y = self.__data_generation(batch_ids)\n",
    "        return X, y\n",
    "\n",
    "    def __load_file(self, file_index):\n",
    "        self.tmp_data = pickle.load(open(self.file_IDs[file_index], 'rb'))\n",
    "        shuffle_idx = np.random.choice(self.tmp_data['data'].shape[0], size = self.tmp_data['data'].shape[0], replace = True)\n",
    "        self.tmp_data['data'] = self.tmp_data['data'][shuffle_idx, :]\n",
    "        self.tmp_data['labels'] = self.tmp_data['labels'][shuffle_idx]\n",
    "        return\n",
    "        #return np.random.shuffle(np.load(self.training_data_folder + '/' + self.file_IDs[file_index]))\n",
    "\n",
    "    def __init_file_shape(self):\n",
    "        init_file = pickle.load(open(self.file_IDs[0], 'rb'))\n",
    "        #print('Init file shape: ', init_file['data'].shape, init_file['labels'].shape)\n",
    "        \n",
    "        self.file_shape_dict = {'inputs': init_file['data'].shape, 'labels': init_file['labels'].shape}\n",
    "        self.batches_per_file = int(self.file_shape_dict['inputs'][0] / self.batch_size)\n",
    "        self.input_dim = self.file_shape_dict['inputs'][1]\n",
    "        \n",
    "        if len(self.file_shape_dict['labels']) > 1:\n",
    "            self.label_dim = self.file_shape_dict['labels'][1]\n",
    "        else:\n",
    "            self.label_dim = 1\n",
    "        return\n",
    "\n",
    "    def __data_generation(self, batch_ids = None):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        X = torch.tensor(self.tmp_data['data'][batch_ids, :]) #tmp_file[batch_ids, :-1]\n",
    "        y = torch.unsqueeze(torch.tensor(self.tmp_data['labels'][batch_ids]),1) #tmp_file[batch_ids, -1]\n",
    "        \n",
    "        if self.label_prelog_cutoff_low is not None:\n",
    "            y[y < np.log(self.label_prelog_cutoff_low)] = np.log(self.label_prelog_cutoff_low)\n",
    "        \n",
    "        if self.label_prelog_cutoff_high is not None:\n",
    "            y[y > np.log(self.label_prelog_cutoff_high)] = np.log(self.label_prelog_cutoff_high)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "ef7b6ea5-4b39-43c1-93e0-d915a3966643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import uuid\n",
    "class TorchMLP(nn.Module):\n",
    "    def __init__(self, network_config = None, input_shape = 10, save_folder = None, generative_model_id = 'ddm'):\n",
    "        super(TorchMLP, self).__init__()\n",
    "        if generative_model_id is not None:\n",
    "            self.model_id = uuid.uuid1().hex + '_' + generative_model_id\n",
    "        else:\n",
    "            self.model_id = None\n",
    "            \n",
    "        self.save_folder = save_folder\n",
    "        self.input_shape = input_shape\n",
    "        self.network_config = network_config\n",
    "        self.activations = {'relu': torch.nn.ReLU(), 'tanh': torch.nn.Tanh()}\n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        self.layers.append(nn.Linear(input_shape, self.network_config['layer_sizes'][0]))\n",
    "        self.layers.append(self.activations[self.network_config['activations'][0]])\n",
    "        for i in range(len(self.network_config['layer_sizes']) - 1):\n",
    "            self.layers.append(nn.Linear(self.network_config['layer_sizes'][i], self.network_config['layer_sizes'][i + 1]))\n",
    "            print(self.network_config['activations'][i + 1])\n",
    "            if i < (len(self.network_config['layer_sizes']) - 2):\n",
    "                self.layers.append(self.activations[self.network_config['activations'][i + 1]])\n",
    "            else:\n",
    "                # skip last activation since\n",
    "                pass\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.layers) - 1):\n",
    "            x = self.layers[i](x)\n",
    "        return self.layers[i + 1](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f04b2bdc-1304-49e4-8bad-fc817f3a5219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'278ed526002e11ecb46da0423f3e9b42_ddm'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e080f5ba-0c7d-4127-b5fd-5aafaaaec99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReLU()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e7814cb7-019c-4513-976b-4765d1083a1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'momentum'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-386ef3b6f726>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'momentum'"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "13dedfb4-cebe-429f-98bc-97cbec562985",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainerTorchMLP:\n",
    "    def __init__(self, \n",
    "                 train_config = None,\n",
    "                 data_loader_train = None,\n",
    "                 data_loader_valid = None,\n",
    "                 torch_model = None,\n",
    "                 output_folder = None,\n",
    "                 warm_start = False,\n",
    "                 allow_abs_folder_generation = False,\n",
    "                 pin_memory = True):\n",
    "        \n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        self.dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        self.train_config = train_config\n",
    "        self.model = torch_model.to(self.dev)\n",
    "        self.output_folder = output_folder\n",
    "        self.allow_abs_folder_generation = allow_abs_folder_generation\n",
    "        self.data_loader_train = data_loader_train\n",
    "        self.data_loader_valid = data_loader_valid\n",
    "        self.warm_start = warm_start\n",
    "        self.pin_memory = pin_memory\n",
    "        \n",
    "        self.__get_loss()\n",
    "        self.__get_optimizer()\n",
    "        self.__load_weights()\n",
    "        \n",
    "    def __get_loss(self):\n",
    "        if self.train_config['loss'] == 'huber':\n",
    "            self.loss_fun = F.huber_loss\n",
    "        elif self.train_config['mse'] == 'mse':\n",
    "            self.loss_fun = F.mse_loss\n",
    "            \n",
    "    def __get_optimizer(self):\n",
    "        if self.train_config['optimizer'] == 'adam':\n",
    "            self.optimizer = optim.Adam(self.model.parameters())        \n",
    "        elif self.train_config['optimizer'] == 'sgd':\n",
    "            self.optimizer = optim.SGD(self.model.parameters())\n",
    "            \n",
    "    def __load_weights(self):\n",
    "        # for warmstart, not implemented at the moment\n",
    "        return\n",
    "    \n",
    "    def train_model(self, save_history = True, save_model = True, verbose = 1):\n",
    "        self.training_history = pd.DataFrame(np.zeros((self.train_config['n_epochs'], 2)), columns = ['epoch', 'val_loss'])\n",
    "        \n",
    "        for epoch in range(self.train_config['n_epochs']):\n",
    "            self.model.train()\n",
    "            cnt = 0\n",
    "            epoch_s_t = time()\n",
    "            #with tqdm.tqdm(self.data_loader_train , unit = 'batch') as tepoch:\n",
    "            for xb, yb in self.data_loader_train:\n",
    "                #tepoch.set_description('Epoch {}'.format(epoch))\n",
    "                if self.pin_memory and self.dev.__str__() == 'cuda':\n",
    "                    xb, yb = xb.cuda(non_blocking = True), yb.cuda(non_blocking = True)\n",
    "                else:\n",
    "                    xb, yb = xb.to(self.dev), yb.to(self.dev)\n",
    "\n",
    "                pred = self.model(xb)\n",
    "                loss = self.loss_fun(pred, yb)\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                if (cnt % 100) == 0 and verbose == 1:\n",
    "                    print('epoch: {}, batch: {} of {}, batch_loss: {}'.format(epoch, cnt, self.data_loader_train.__len__(), loss))\n",
    "                elif (cnt % 1000) == 0 and verbose == 2:\n",
    "                    print('epoch: {}, batch: {} of {}, batch_loss: {}'.format(epoch, cnt, self.data_loader_train.__len__(), loss))\n",
    "                cnt += 1\n",
    "\n",
    "            print('Epoch took {} seconds'.format(time() - epoch_s_t))\n",
    "            print('STARTING VALIDATION:')\n",
    "            self.model.eval()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                valid_loss = sum(self.loss_fun(self.model(xb.to(self.dev)), yb.to(self.dev)) for xb, yb in self.data_loader_valid) / self.data_loader_valid.__len__()\n",
    "            print('epoch {} / {}, validation_loss: {:2.4}'.format(epoch, self.train_config['n_epochs'], valid_loss))\n",
    "            \n",
    "            self.training_history.values[epoch, :] = [epoch, valid_loss]\n",
    "            \n",
    "        if save_model == True:\n",
    "            print('Saving model and training history')\n",
    "            pd.DataFrame(self.training_history).to_csv(self.output_folder + \"/\" + self.model.model_id + \"_torch_training_history.csv\")\n",
    "            torch.save(self.model.state_dict(), self.output_folder + \"/\" + self.model.model_id + \"_torch_state_dict.pt\")\n",
    "            \n",
    "class LoadTorchMLPInfer:\n",
    "    def __init__(file_path = None,\n",
    "                 network_config = None,\n",
    "                 input_dim = None):\n",
    "        \n",
    "        \n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        self.dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        self.model_file_path = file_path\n",
    "        self.network_config = network_config\n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        self.net = TorchMLP(network_config = self.network_config,\n",
    "                            input_dim = self.input_dim,\n",
    "                            generative_model_id = None)\n",
    "        self.net.load_state_dict(torch.load(self.model_file_path))\n",
    "        self.net.to(dev)\n",
    "        self.net.eval()\n",
    "        \n",
    "    def predict_on_batch(x = None):\n",
    "        return self.net(torch.from_numpy(x).to(dev))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7cb9e958-d96b-4aaa-b088-f5e9729bdcbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh\n",
      "tanh\n",
      "linear\n",
      "TorchMLP(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=6, out_features=100, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (5): Tanh()\n",
      "    (6): Linear(in_features=100, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Specify a path\n",
    "PATH = \"data/torch_models/state_dict_model.pt\"\n",
    "\n",
    "# Save\n",
    "torch.save(net.state_dict(), PATH)\n",
    "\n",
    "# Load\n",
    "model = TorchMLP(network_config = {'layer_types': ['dense', 'dense', 'dense'],\n",
    "                                  'layer_sizes': [100, 100, 100, 1],\n",
    "                                  'activations': ['tanh', 'tanh', 'tanh', 'linear'],\n",
    "                                  'loss': ['huber'],\n",
    "                                  'callbacks': ['checkpoint', 'earlystopping', 'reducelr']}, input_shape = 6)\n",
    "#model.load_state_dict(torch.load(PATH))\n",
    "#model.eval()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e25e297-291b-47a5-bec1-0c8523342c84",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-87f2ec5363b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ms_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0me_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ms_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/software/miniconda3/envs/lanfactory/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-c262047ed82d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'activations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "input_tensor = torch.Tensor(np.tile([0.0, 0.0, 0.0, 0.0, 0.0, 0.0], (1000, 1))) # .to(dev)\n",
    "s_t = time()\n",
    "for i in range(100):\n",
    "    model(input_tensor)\n",
    "e_t = (time() - s_t) / 100\n",
    "print(e_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "1d03688b-d325-40f8-8cc4-1819f4ab421c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide a unique identifier for the particular files you need from the training_data_folder\n",
    "training_file_identifier = 'ddm'\n",
    "train_file_excluder = ['par2', 'seq2']\n",
    "\n",
    "# Specify training data folder:\n",
    "training_data_folder = '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/lan_mlp/training_data_0_nbins_0_n_200000'\n",
    "\n",
    "# Where do you want to save config files?\n",
    "network_train_config_save_folder = '/users/afengler/data/proj_lan_pipeline/LAN_scripts/config_files/'\n",
    "\n",
    "# Name of the config file\n",
    "network_train_config_save_name = 'network_train_config_ddm_nsim_200000_dt_0005_nps_500_npts_2000.pickle'\n",
    "\n",
    "# Get list of training files\n",
    "train_val_split = 0.9\n",
    "file_list = os.listdir(training_data_folder)\n",
    "valid_file_list = np.array([training_data_folder + '/' + \\\n",
    "                       file_ for file_ in file_list if (training_file_identifier in file_ and train_file_excluder[0] not in file_ and train_file_excluder[1] not in file_ )])\n",
    "val_idx_cutoff = int(0.9 * len(valid_file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47abcab9-ab58-4103-acfb-8016dd59e882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "bfed8777-58fc-478d-9b0a-1d567a724c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh\n",
      "tanh\n",
      "linear\n",
      "TorchMLP(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=6, out_features=100, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (5): Tanh()\n",
      "    (6): Linear(in_features=100, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'fadedeb8007811ecb46da0423f3e9b42_ddm'"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_network_config = {'layer_types': ['dense', 'dense', 'dense'],\n",
    "                                 'layer_sizes': [100, 100, 100, 1],\n",
    "                                 'activations': ['tanh', 'tanh', 'tanh', 'linear'],\n",
    "                                 'loss': ['huber'],\n",
    "                                 'callbacks': ['checkpoint', 'earlystopping', 'reducelr']}\n",
    "\n",
    "my_train_config = {'batch_size': 100000,\n",
    "                   'n_epochs': 5,\n",
    "                   'optimizer': 'adam',\n",
    "                   'learning_rate': 0.002,\n",
    "                   'loss': 'huber',\n",
    "                    'metrics': None,\n",
    "                    'callbacks': None}\n",
    "\n",
    "my_train_data = Dataset(file_IDs = valid_file_list[:val_idx_cutoff],\n",
    "                        batch_size = my_train_config['batch_size'],)\n",
    "my_valid_data = Dataset(file_IDs = valid_file_list[val_idx_cutoff:],\n",
    "                        batch_size = my_train_config['batch_size'])\n",
    "\n",
    "my_train_loader = torch.utils.data.DataLoader(my_train_data, batch_size = None, shuffle = True, num_workers = 10, pin_memory = True)\n",
    "my_valid_loader = torch.utils.data.DataLoader(my_train_data, batch_size = None, shuffle = True, num_workers = 10, pin_memory = True)\n",
    "\n",
    "\n",
    "net = TorchMLP(network_config = my_network_config, input_shape = 6)\n",
    "print(net)\n",
    "\n",
    "trainer = ModelTrainerTorchMLP(train_config = my_train_config,\n",
    "                               data_loader_train = my_train_loader,\n",
    "                               data_loader_valid = my_valid_loader,\n",
    "                               torch_model = net,\n",
    "                               output_folder = '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/torch_models/',\n",
    "                               warm_start = False,\n",
    "                               allow_abs_folder_generation = False)  \n",
    "\n",
    "trainer.model.model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "e2f76ff8-dd44-4c70-b975-4634f2fbd3cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute 'input_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-211-ed7d389f692b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_train_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'input_dim'"
     ]
    }
   ],
   "source": [
    "my_train_loader.input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7bcab805-e2f8-440c-ad59-720cf73c1996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7cdd1f34003211ecb46da0423f3e9b42_ddm'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5f8551-2e90-44c8-a138-455e5331ed01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch: 0 of 3510, batch_loss: 3.4872536659240723\n",
      "epoch: 0, batch: 100 of 3510, batch_loss: 1.926230549812317\n",
      "epoch: 0, batch: 200 of 3510, batch_loss: 0.6017950177192688\n",
      "epoch: 0, batch: 300 of 3510, batch_loss: 0.464552640914917\n",
      "epoch: 0, batch: 400 of 3510, batch_loss: 0.34960973262786865\n",
      "epoch: 0, batch: 500 of 3510, batch_loss: 0.28977394104003906\n",
      "epoch: 0, batch: 600 of 3510, batch_loss: 0.23863887786865234\n",
      "epoch: 0, batch: 700 of 3510, batch_loss: 0.21052594482898712\n",
      "epoch: 0, batch: 800 of 3510, batch_loss: 0.18897585570812225\n",
      "epoch: 0, batch: 900 of 3510, batch_loss: 0.18021658062934875\n",
      "epoch: 0, batch: 1000 of 3510, batch_loss: 0.17104624211788177\n",
      "epoch: 0, batch: 1100 of 3510, batch_loss: 0.15574601292610168\n",
      "epoch: 0, batch: 1200 of 3510, batch_loss: 0.15176177024841309\n",
      "epoch: 0, batch: 1300 of 3510, batch_loss: 0.14404910802841187\n",
      "epoch: 0, batch: 1400 of 3510, batch_loss: 0.13654905557632446\n",
      "epoch: 0, batch: 1500 of 3510, batch_loss: 0.13527114689350128\n",
      "epoch: 0, batch: 1600 of 3510, batch_loss: 0.12878043949604034\n"
     ]
    }
   ],
   "source": [
    "trainer.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c4fccd1d-8ae4-44c9-a996-e2c1ec582106",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got multiple values for argument 'file_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-30bfe566ea87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m inference_model = LoadTorchMLPInfer(file_path = '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/torch_models/' + trainer.model.model_id + '_torch_state_dict.pt', \n\u001b[1;32m      2\u001b[0m                                     \u001b[0mnetwork_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_network_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                                     input_dim = 6)\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got multiple values for argument 'file_path'"
     ]
    }
   ],
   "source": [
    "inference_model = LoadTorchMLPInfer(file_path = '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/torch_models/' + trainer.model.model_id + '_torch_state_dict.pt', \n",
    "                                    network_config = my_network_config,\n",
    "                                    input_dim = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7e04e27f-c58b-4af3-9113-688edab7e78b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict_on_batch() takes from 0 to 1 positional arguments but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-82b0fe3af1cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minference_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: predict_on_batch() takes from 0 to 1 positional arguments but 2 were given"
     ]
    }
   ],
   "source": [
    "inference_model.predict_on_batch(np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0], dtype = np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "0896a77b-ab63-42f1-991c-61d665bf1b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadTorchMLPInfer:\n",
    "    def __init__(self, \n",
    "                 model_file_path = None,\n",
    "                 network_config = None,\n",
    "                 input_dim = None):\n",
    "        \n",
    "        \n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        self.dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        self.model_file_path = model_file_path\n",
    "        self.network_config = network_config\n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        self.net = TorchMLP(network_config = self.network_config,\n",
    "                            input_shape = self.input_dim,\n",
    "                            generative_model_id = None)\n",
    "        self.net.load_state_dict(torch.load(self.model_file_path))\n",
    "        #self.net.half()\n",
    "        self.net.to(self.dev)\n",
    "        self.net.eval()\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def predict_on_batch(self, x = None):\n",
    "        return self.net(torch.from_numpy(x).to(self.dev)).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "37b55b22-8697-4a2e-963f-c12cf08a0982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh\n",
      "tanh\n",
      "linear\n"
     ]
    }
   ],
   "source": [
    "inference_model = LoadTorchMLPInfer(model_file_path = '/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/torch_models/' + trainer.model.model_id + '_torch_state_dict.pt', \n",
    "                                    network_config = my_network_config,\n",
    "                                    input_dim = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "0a4529ee-debb-42e7-87cb-ac83d5dd8959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/torch_models/48dbe2ea004d11ecb46da0423f3e9b42_ddm_torch_state_dict.pt'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/torch_models/' + trainer.model.model_id + '_torch_state_dict.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "48878ba0-134d-4878-ac63-ad48dbc15eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00020326852798461915\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros((100, 6), dtype = np.float32) # , np.zeros((1000, 6), dtype = np.float), np.zeros((2000, 6), dtype = np.float32)]\n",
    "#x_tensor = torch.tensor(x).to(inference_model.dev)\n",
    "s_t = time()\n",
    "for i in range(100):\n",
    "    inference_model.predict_on_batch(x = x) # PYTORCH \n",
    "    #inference_model.net(x = x_tensor)\n",
    "print((time() - s_t) / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "18eedbf5-f834-4b44-ac27-27ddd740912e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "f26a2c7b-7708-497e-9638-d55ae5c9c652",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_keras_model = keras.models.load_model('/users/afengler/data/proj_lan_pipeline/LAN_scripts/data/models/02938a2cf72911eb9d58a0423f3e9be0_ddm_ckpt.h5', compile = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "36dd1b62-deb1-49da-a905-2e88561ff5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002927823066711426\n"
     ]
    }
   ],
   "source": [
    "s_t = time()\n",
    "for i in range(100):\n",
    "    my_keras_model.predict_on_batch(x)\n",
    "    #inference_model.net(x = x_tensor)\n",
    "print((time() - s_t) / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dc0a5c-d44a-4b8c-a808-affd82c28a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               700       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 21,001\n",
      "Trainable params: 21,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfd508c-9aab-439e-be56-5c02e9b852b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lanfactory",
   "language": "python",
   "name": "lanfactory"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
